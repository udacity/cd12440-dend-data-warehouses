{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Lesson 2: Exercise 3 - Generate an ER Diagram from DDL\n",
    "\n",
    "## Goal\n",
    "\n",
    "Produce a **schema diagram** (Mermaid ER) from your DDL so you can include it in your **final project report**. This notebook parses `CREATE TABLE` statements and infers **fact-to-dimension relationships** by scanning `*_sk` columns.\n",
    "\n",
    "## What You Will Build\n",
    "\n",
    "A process that:\n",
    "\n",
    "1. Reads SQL DDL (inline or from files)\n",
    "2. Parses `CREATE TABLE` statements to collect table names and columns\n",
    "3. Identifies columns ending with `_sk` as foreign key hints\n",
    "4. Produces a Mermaid ER diagram with tables and relationships\n",
    "5. Outputs the diagram to a `.mmd` file for use in documentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "Run this cell first to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Imports\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "Set up paths for input DDL and output diagram files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= CONFIG\n",
    "BASE_DIR = os.getenv(\"PROJECT_BASE_DIR\", \".\")\n",
    "OUTPUT_MERMAID = os.path.join(BASE_DIR, \"schema.mmd\")\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"   - BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"   - Output file: {OUTPUT_MERMAID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions for Reporting\n",
    "\n",
    "These functions match patterns used in the final project for generating markdown reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Report Helper Functions (same pattern as project solution)\n",
    "\n",
    "def md_table(rows: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Convert a list of dicts to a Markdown table string.\n",
    "    \n",
    "    This is the same helper used in the final project for generating reports.\n",
    "    \n",
    "    Args:\n",
    "        rows: List of dictionaries with consistent keys\n",
    "    \n",
    "    Returns:\n",
    "        Markdown table as a string\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        return \"_no rows_\\n\"\n",
    "    cols = list(rows[0].keys())\n",
    "    lines = [\n",
    "        \"| \" + \" | \".join(cols) + \" |\",\n",
    "        \"| \" + \" | \".join([\"---\"] * len(cols)) + \" |\"\n",
    "    ]\n",
    "    for r in rows:\n",
    "        lines.append(\"| \" + \" | \".join(str(r[c]) for c in cols) + \" |\")\n",
    "    return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "\n",
    "print(\"Helper function defined: md_table()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parser-header",
   "metadata": {},
   "source": [
    "---\n",
    "## DDL Parser Functions\n",
    "\n",
    "Functions to extract table names and columns from `CREATE TABLE` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parser-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= DDL Parser\n",
    "\n",
    "# Regex to match CREATE TABLE statements\n",
    "CREATE_TABLE_RE = re.compile(\n",
    "    r'CREATE\\s+TABLE\\s+(?:IF\\s+NOT\\s+EXISTS\\s+)?(?P<tbl_name>[A-Za-z0-9_\\.\"]+)\\s*\\((?P<body>.*?)\\)\\s*;',\n",
    "    re.IGNORECASE | re.DOTALL,\n",
    ")\n",
    "\n",
    "# Regex to match column definitions\n",
    "COLUMN_RE = re.compile(\n",
    "    r'^\\s*(?P<col>[A-Za-z0-9_\"]+)\\s+(?P<type>[A-Za-z0-9_\\(\\), ]+?)(?:,|$)',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Lines to skip (constraints, not columns)\n",
    "SKIP_PREFIXES = (\"PRIMARY\", \"UNIQUE\", \"FOREIGN\", \"CONSTRAINT\", \"DISTKEY\", \"SORTKEY\", \"--\")\n",
    "\n",
    "\n",
    "def parse_tables(sql_text: str) -> Dict[Tuple[str, str], List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Parse CREATE TABLE statements from SQL text.\n",
    "    \n",
    "    Args:\n",
    "        sql_text: String containing one or more CREATE TABLE statements\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping (schema, table_name) to list of (column_name, data_type)\n",
    "    \"\"\"\n",
    "    tables = {}\n",
    "    \n",
    "    for match in CREATE_TABLE_RE.finditer(sql_text):\n",
    "        full_name = match.group(\"tbl_name\").strip('\"')\n",
    "        body = match.group(\"body\")\n",
    "        \n",
    "        # Parse schema.table format\n",
    "        if \".\" in full_name:\n",
    "            schema, table_name = full_name.split(\".\", 1)\n",
    "        else:\n",
    "            schema = \"\"\n",
    "            table_name = full_name\n",
    "        \n",
    "        # Extract columns\n",
    "        columns = []\n",
    "        for line in body.splitlines():\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Skip empty lines and constraints\n",
    "            if not line or line.upper().startswith(SKIP_PREFIXES):\n",
    "                continue\n",
    "            \n",
    "            col_match = COLUMN_RE.match(line)\n",
    "            if col_match:\n",
    "                col_name = col_match.group(\"col\").strip('\"')\n",
    "                col_type = col_match.group(\"type\").strip().split()[0]  # First word of type\n",
    "                columns.append((col_name, col_type))\n",
    "        \n",
    "        tables[(schema, table_name)] = columns\n",
    "    \n",
    "    return tables\n",
    "\n",
    "\n",
    "print(\"Parser function defined: parse_tables()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Relationship Inference\n",
    "\n",
    "Infer fact-to-dimension relationships by matching `*_sk` columns in fact tables to dimension table names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-todo",
   "metadata": {},
   "source": [
    "**TODO**: Complete the `infer_relationships` function. The logic should:\n",
    "\n",
    "1. Find all dimension tables (tables starting with `dim_prefix`)\n",
    "2. Loop through all fact tables (tables starting with `fact_prefix`)\n",
    "3. For each column ending with `_sk` in a fact table:\n",
    "   - Derive the dimension name by stripping `_sk` and adding `dim_prefix`\n",
    "   - Example: `rider_sk` -> `dw_dim_rider`\n",
    "   - If that dimension exists, add a relationship tuple\n",
    "4. Return a list of `(fact_table, dim_table, column_name)` tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Relationship Inference\n",
    "\n",
    "def infer_relationships(\n",
    "    tables: Dict[Tuple[str, str], List[Tuple[str, str]]],\n",
    "    dim_prefix: str = \"dw_dim_\",\n",
    "    fact_prefix: str = \"dw_fact_\"\n",
    ") -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Infer relationships between fact and dimension tables.\n",
    "    \n",
    "    Logic: If a fact table has a column like `rider_sk`, look for `dw_dim_rider`.\n",
    "    \n",
    "    Args:\n",
    "        tables: Output from parse_tables()\n",
    "        dim_prefix: Prefix for dimension tables (default: \"dw_dim_\")\n",
    "        fact_prefix: Prefix for fact tables (default: \"dw_fact_\")\n",
    "    \n",
    "    Returns:\n",
    "        List of (fact_table, dim_table, column_name) tuples\n",
    "    \"\"\"\n",
    "    # TODO: Find all dimension tables (hint: use a set comprehension)\n",
    "    dims = set()\n",
    "    \n",
    "    relationships = []\n",
    "    \n",
    "    # TODO: Loop through tables and find fact tables\n",
    "    for (schema, table_name), columns in tables.items():\n",
    "        # TODO: Skip non-fact tables\n",
    "        pass\n",
    "        \n",
    "        # TODO: For each column ending with \"_sk\", check if matching dimension exists\n",
    "        for col_name, _ in columns:\n",
    "            pass\n",
    "    \n",
    "    return relationships\n",
    "\n",
    "\n",
    "print(\"Inference function defined: infer_relationships()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mermaid-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Mermaid Generator\n",
    "\n",
    "Generate Mermaid ER diagram syntax from parsed tables and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mermaid-todo",
   "metadata": {},
   "source": [
    "**TODO**: Complete the `generate_mermaid` function. The output should:\n",
    "\n",
    "1. Start with `erDiagram`\n",
    "2. For each table, create a block like:\n",
    "   ```\n",
    "   table_name {\n",
    "       TYPE column_name\n",
    "       TYPE column_name\n",
    "   }\n",
    "   ```\n",
    "3. For each relationship, add a line like:\n",
    "   ```\n",
    "   dim_table ||--o{ fact_table : \"fk_column\"\n",
    "   ```\n",
    "   (This means \"one dim row to many fact rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mermaid-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Mermaid Generator\n",
    "\n",
    "def generate_mermaid(\n",
    "    tables: Dict[Tuple[str, str], List[Tuple[str, str]]],\n",
    "    relationships: List[Tuple[str, str, str]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate Mermaid ER diagram syntax.\n",
    "    \n",
    "    Args:\n",
    "        tables: Output from parse_tables()\n",
    "        relationships: Output from infer_relationships()\n",
    "    \n",
    "    Returns:\n",
    "        String containing the Mermaid diagram\n",
    "    \"\"\"\n",
    "    lines = [\"erDiagram\"]\n",
    "    \n",
    "    # TODO: Generate table blocks\n",
    "    for (schema, table_name), columns in sorted(tables.items()):\n",
    "        # TODO: Add table header\n",
    "        # TODO: Add columns (format: \"        TYPE column_name\")\n",
    "        # TODO: Close table block\n",
    "        pass\n",
    "    \n",
    "    # TODO: Generate relationships\n",
    "    # Format: dim_table ||--o{ fact_table : \"column_name\"\n",
    "    for fact_table, dim_table, col_name in relationships:\n",
    "        pass\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "print(\"Generator function defined: generate_mermaid()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Sample DDL\n",
    "\n",
    "Use the DDL from Exercises 1 and 2, plus additional dimension tables to create a complete schema.\n",
    "\n",
    "Note: We use the `public` schema with `dw_` prefixes to match the pattern from Exercises 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Sample DDL (from Exercises 1 and 2, plus supporting dims)\n",
    "\n",
    "SAMPLE_DDL = \"\"\"\n",
    "-- =============================================================\n",
    "-- DIMENSION TABLES\n",
    "-- =============================================================\n",
    "\n",
    "CREATE TABLE public.dw_dim_rider (\n",
    "    rider_sk        BIGINT IDENTITY(1,1),\n",
    "    rider_id        VARCHAR(32),\n",
    "    rider_segment   VARCHAR(16),\n",
    "    effective_from  TIMESTAMP,\n",
    "    effective_to    TIMESTAMP,\n",
    "    is_current      BOOLEAN,\n",
    "    PRIMARY KEY (rider_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_route (\n",
    "    route_sk   BIGINT IDENTITY(1,1),\n",
    "    route_id   VARCHAR(32),\n",
    "    PRIMARY KEY (route_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_mode (\n",
    "    mode_sk   BIGINT IDENTITY(1,1),\n",
    "    mode      VARCHAR(32),\n",
    "    PRIMARY KEY (mode_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_station (\n",
    "    station_sk  BIGINT IDENTITY(1,1),\n",
    "    station_id  VARCHAR(32),\n",
    "    city        VARCHAR(64),\n",
    "    province    VARCHAR(32),\n",
    "    latitude    DECIMAL(10,6),\n",
    "    longitude   DECIMAL(10,6),\n",
    "    PRIMARY KEY (station_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_date (\n",
    "    date_key     INTEGER,\n",
    "    date_actual  DATE,\n",
    "    year         SMALLINT,\n",
    "    quarter      SMALLINT,\n",
    "    month        SMALLINT,\n",
    "    day          SMALLINT,\n",
    "    day_of_week  SMALLINT,\n",
    "    is_weekend   BOOLEAN,\n",
    "    PRIMARY KEY (date_key)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_payment_method (\n",
    "    payment_method_sk  BIGINT IDENTITY(1,1),\n",
    "    payment_method     VARCHAR(32),\n",
    "    PRIMARY KEY (payment_method_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_fare_class (\n",
    "    fare_class_sk  BIGINT IDENTITY(1,1),\n",
    "    fare_class     VARCHAR(32),\n",
    "    PRIMARY KEY (fare_class_sk)\n",
    ");\n",
    "\n",
    "-- =============================================================\n",
    "-- FACT TABLES\n",
    "-- =============================================================\n",
    "\n",
    "CREATE TABLE public.dw_fact_trips (\n",
    "    trip_sk                 BIGINT IDENTITY(1,1),\n",
    "    trip_id                 VARCHAR(32),\n",
    "    rider_sk                BIGINT,\n",
    "    route_sk                BIGINT,\n",
    "    mode_sk                 BIGINT,\n",
    "    origin_station_sk       BIGINT,\n",
    "    destination_station_sk  BIGINT,\n",
    "    board_date_key          INTEGER,\n",
    "    alight_date_key         INTEGER,\n",
    "    transfers               INTEGER,\n",
    "    zones_charged           INTEGER,\n",
    "    distance_km             DECIMAL(10,2),\n",
    "    total_fare_cad          DECIMAL(12,2),\n",
    "    payment_method_sk       BIGINT,\n",
    "    fare_class_sk           BIGINT,\n",
    "    on_time_arrival         BOOLEAN,\n",
    "    service_disruption      BOOLEAN\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sample DDL defined ({len(SAMPLE_DDL)} characters)\")\n",
    "print(\"Contains: dw_dim_rider, dw_dim_route, dw_dim_mode, dw_dim_station, dw_dim_date,\")\n",
    "print(\"          dw_dim_payment_method, dw_dim_fare_class, dw_fact_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parse-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Parse the DDL\n",
    "\n",
    "Extract tables and columns from the sample DDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = parse_tables(SAMPLE_DDL)\n",
    "\n",
    "print(f\"Parsed {len(tables)} tables:\")\n",
    "print(\"-\" * 40)\n",
    "for (schema, name), columns in sorted(tables.items()):\n",
    "    print(f\"  {schema}.{name}: {len(columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infer-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Infer Relationships\n",
    "\n",
    "Find fact-to-dimension relationships based on `*_sk` column naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infer-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = infer_relationships(tables)\n",
    "\n",
    "print(f\"Inferred {len(relationships)} relationships:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Display as a table using md_table pattern\n",
    "rel_data = [\n",
    "    {\"dimension\": dim, \"fact\": fact, \"fk_column\": col}\n",
    "    for fact, dim, col in relationships\n",
    "]\n",
    "print(md_table(rel_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Generate the Mermaid Diagram\n",
    "\n",
    "Create the Mermaid ER diagram syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "mermaid_diagram = generate_mermaid(tables, relationships)\n",
    "\n",
    "print(\"Generated Mermaid ER Diagram:\")\n",
    "print(\"=\" * 60)\n",
    "print(mermaid_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Save to File\n",
    "\n",
    "Write the diagram to a `.mmd` file for use in documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(OUTPUT_MERMAID)\n",
    "output_path.write_text(mermaid_diagram, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Diagram saved to: {output_path.absolute()}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Preview at https://mermaid.live\")\n",
    "print(\"  2. Or use VS Code with Mermaid extension\")\n",
    "print(\"  3. Or render to PNG: mmdc -i schema.mmd -o schema.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Display in Notebook\n",
    "\n",
    "Display the Mermaid code for easy copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the raw Mermaid code in a code block for easy copying\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(f\"\"\"```mermaid\n",
    "{mermaid_diagram}\n",
    "```\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to Use This in Your Project\n",
    "\n",
    "### Option 1: From SQL Files\n",
    "\n",
    "```python\n",
    "# Read DDL from files\n",
    "sql_files = [\"dw_dim_rider.sql\", \"dw_dim_station.sql\", \"dw_fact_trips.sql\"]\n",
    "combined_sql = \"\\n\\n\".join(Path(f).read_text() for f in sql_files)\n",
    "\n",
    "tables = parse_tables(combined_sql)\n",
    "relationships = infer_relationships(tables)\n",
    "mermaid = generate_mermaid(tables, relationships)\n",
    "\n",
    "Path(\"my_schema.mmd\").write_text(mermaid)\n",
    "```\n",
    "\n",
    "### Option 2: Use Pre-made Diagram\n",
    "\n",
    "The final project includes `project-mermaid-diagram.md` which you can use directly:\n",
    "\n",
    "```python\n",
    "MERMAID_MD = os.path.join(BASE_DIR, \"project-mermaid-diagram.md\")\n",
    "if os.path.exists(MERMAID_MD):\n",
    "    with open(MERMAID_MD, \"r\", encoding=\"utf-8\") as f: \n",
    "        mermaid = f.read().strip()\n",
    "```\n",
    "\n",
    "### Tips for Your Final Report\n",
    "\n",
    "1. **Include the Mermaid source** in your documentation (renders in GitHub, Notion, etc.)\n",
    "2. **Export to PNG/SVG** for PDF reports using Mermaid CLI\n",
    "3. **Document the grain** for each fact table in accompanying text\n",
    "4. **Highlight conformed dimensions** that span multiple facts\n",
    "\n",
    "### Naming Convention\n",
    "\n",
    "This exercise uses the same naming convention as the final project:\n",
    "- All tables in the `public` schema\n",
    "- Dimension tables prefixed with `dw_dim_` (e.g., `dw_dim_rider`)\n",
    "- Fact tables prefixed with `dw_fact_` (e.g., `dw_fact_trips`)\n",
    "\n",
    "### Connection to Project Solution\n",
    "\n",
    "The project solution uses `md_table()` to generate markdown tables in the final report. The pattern you learned here will help you understand and extend the project's reporting capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
