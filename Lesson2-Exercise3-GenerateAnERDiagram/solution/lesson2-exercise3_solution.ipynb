{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Lesson 2: Exercise 3 Solution - Generate an ER Diagram from DDL\n",
    "\n",
    "## Goal\n",
    "\n",
    "Produce a **schema diagram** (Mermaid ER) from your DDL so you can include it in your **final project report**. This notebook parses `CREATE TABLE` statements and infers **fact-to-dimension relationships** by scanning `*_sk` columns.\n",
    "\n",
    "## What You Will Build\n",
    "\n",
    "A process that:\n",
    "\n",
    "1. Reads SQL DDL (inline or from files)\n",
    "2. Parses `CREATE TABLE` statements to collect table names and columns\n",
    "3. Identifies columns ending with `_sk` as foreign key hints\n",
    "4. Produces a Mermaid ER diagram with tables and relationships\n",
    "5. Outputs the diagram to a `.mmd` file for use in documentation\n",
    "\n",
    "\n",
    "### Acceptance Criteria\n",
    "\n",
    "- Diagram shows `dw_dim_rider` and `dw_fact_trips` with an edge from trips to rider\n",
    "- Works even if **no explicit foreign keys** are declared in SQL\n",
    "- Output can be previewed at [Mermaid Live](https://mermaid.live) or in VS Code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032a313-029f-43e4-a5f2-b514a4bfdef3",
   "metadata": {},
   "source": [
    "## Lesson 2 Exercise 3: Generate an ER Diagram Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "Run this cell first to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# ========= Imports\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "Set up paths for input DDL and output diagram files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "   - BASE_DIR: .\n",
      "   - Output file: ./schema.mmd\n"
     ]
    }
   ],
   "source": [
    "# ========= CONFIG\n",
    "BASE_DIR = os.getenv(\"PROJECT_BASE_DIR\", \".\")\n",
    "OUTPUT_MERMAID = os.path.join(BASE_DIR, \"schema.mmd\")\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"   - BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"   - Output file: {OUTPUT_MERMAID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions for Reporting\n",
    "\n",
    "These functions match patterns used in the final project for generating markdown reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "helpers-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined: md_table()\n"
     ]
    }
   ],
   "source": [
    "# ========= Report Helper Functions (same pattern as project solution)\n",
    "\n",
    "def md_table(rows: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Convert a list of dicts to a Markdown table string.\n",
    "    \n",
    "    This is the same helper used in the final project for generating reports.\n",
    "    \n",
    "    Args:\n",
    "        rows: List of dictionaries with consistent keys\n",
    "    \n",
    "    Returns:\n",
    "        Markdown table as a string\n",
    "    \"\"\"\n",
    "    if not rows:\n",
    "        return \"_no rows_\\n\"\n",
    "    cols = list(rows[0].keys())\n",
    "    lines = [\n",
    "        \"| \" + \" | \".join(cols) + \" |\",\n",
    "        \"| \" + \" | \".join([\"---\"] * len(cols)) + \" |\"\n",
    "    ]\n",
    "    for r in rows:\n",
    "        lines.append(\"| \" + \" | \".join(str(r[c]) for c in cols) + \" |\")\n",
    "    return \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "\n",
    "print(\"Helper function defined: md_table()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parser-header",
   "metadata": {},
   "source": [
    "---\n",
    "## DDL Parser Functions\n",
    "\n",
    "Functions to extract table names and columns from `CREATE TABLE` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parser-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser function defined: parse_tables()\n"
     ]
    }
   ],
   "source": [
    "# ========= DDL Parser\n",
    "\n",
    "# Regex to match CREATE TABLE statements\n",
    "CREATE_TABLE_RE = re.compile(\n",
    "    r'CREATE\\s+TABLE\\s+(?:IF\\s+NOT\\s+EXISTS\\s+)?(?P<tbl_name>[A-Za-z0-9_\\.\"]+)\\s*\\((?P<body>.*?)\\)\\s*;',\n",
    "    re.IGNORECASE | re.DOTALL,\n",
    ")\n",
    "\n",
    "# Regex to match column definitions\n",
    "COLUMN_RE = re.compile(\n",
    "    r'^\\s*(?P<col>[A-Za-z0-9_\"]+)\\s+(?P<type>[A-Za-z0-9_\\(\\), ]+?)(?:,|$)',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Lines to skip (constraints, not columns)\n",
    "SKIP_PREFIXES = (\"PRIMARY\", \"UNIQUE\", \"FOREIGN\", \"CONSTRAINT\", \"DISTKEY\", \"SORTKEY\", \"--\")\n",
    "\n",
    "\n",
    "def parse_tables(sql_text: str) -> Dict[Tuple[str, str], List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Parse CREATE TABLE statements from SQL text.\n",
    "    \n",
    "    Args:\n",
    "        sql_text: String containing one or more CREATE TABLE statements\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping (schema, table_name) to list of (column_name, data_type)\n",
    "    \"\"\"\n",
    "    tables = {}\n",
    "    \n",
    "    for match in CREATE_TABLE_RE.finditer(sql_text):\n",
    "        full_name = match.group(\"tbl_name\").strip('\"')\n",
    "        body = match.group(\"body\")\n",
    "        \n",
    "        # Parse schema.table format\n",
    "        if \".\" in full_name:\n",
    "            schema, table_name = full_name.split(\".\", 1)\n",
    "        else:\n",
    "            schema = \"\"\n",
    "            table_name = full_name\n",
    "        \n",
    "        # Extract columns\n",
    "        columns = []\n",
    "        for line in body.splitlines():\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Skip empty lines and constraints\n",
    "            if not line or line.upper().startswith(SKIP_PREFIXES):\n",
    "                continue\n",
    "            \n",
    "            col_match = COLUMN_RE.match(line)\n",
    "            if col_match:\n",
    "                col_name = col_match.group(\"col\").strip('\"')\n",
    "                col_type = col_match.group(\"type\").strip().split()[0]  # First word of type\n",
    "                columns.append((col_name, col_type))\n",
    "        \n",
    "        tables[(schema, table_name)] = columns\n",
    "    \n",
    "    return tables\n",
    "\n",
    "\n",
    "print(\"Parser function defined: parse_tables()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Relationship Inference\n",
    "\n",
    "Infer fact-to-dimension relationships by matching `*_sk` columns in fact tables to dimension table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inference-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference function defined: infer_relationships()\n"
     ]
    }
   ],
   "source": [
    "# ========= Relationship Inference\n",
    "\n",
    "def infer_relationships(\n",
    "    tables: Dict[Tuple[str, str], List[Tuple[str, str]]],\n",
    "    dim_prefix: str = \"dw_dim_\",\n",
    "    fact_prefix: str = \"dw_fact_\"\n",
    ") -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Infer relationships between fact and dimension tables.\n",
    "    \n",
    "    Logic: If a fact table has a column like `rider_sk`, look for `dw_dim_rider`.\n",
    "    \n",
    "    Args:\n",
    "        tables: Output from parse_tables()\n",
    "        dim_prefix: Prefix for dimension tables (default: \"dw_dim_\")\n",
    "        fact_prefix: Prefix for fact tables (default: \"dw_fact_\")\n",
    "    \n",
    "    Returns:\n",
    "        List of (fact_table, dim_table, column_name) tuples\n",
    "    \"\"\"\n",
    "    # Find all dimension tables\n",
    "    dims = {name for (_, name) in tables if name.startswith(dim_prefix)}\n",
    "    \n",
    "    relationships = []\n",
    "    \n",
    "    for (schema, table_name), columns in tables.items():\n",
    "        # Only process fact tables\n",
    "        if not table_name.startswith(fact_prefix):\n",
    "            continue\n",
    "        \n",
    "        for col_name, _ in columns:\n",
    "            # Look for *_sk columns\n",
    "            if col_name.endswith(\"_sk\"):\n",
    "                # Derive dimension name: rider_sk -> dw_dim_rider\n",
    "                dim_candidate = f\"{dim_prefix}{col_name[:-3]}\"  # Strip \"_sk\"\n",
    "                \n",
    "                if dim_candidate in dims:\n",
    "                    relationships.append((table_name, dim_candidate, col_name))\n",
    "    \n",
    "    return relationships\n",
    "\n",
    "\n",
    "print(\"Inference function defined: infer_relationships()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mermaid-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Mermaid Generator\n",
    "\n",
    "Generate Mermaid ER diagram syntax from parsed tables and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mermaid-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator function defined: generate_mermaid()\n"
     ]
    }
   ],
   "source": [
    "# ========= Mermaid Generator\n",
    "\n",
    "def generate_mermaid(\n",
    "    tables: Dict[Tuple[str, str], List[Tuple[str, str]]],\n",
    "    relationships: List[Tuple[str, str, str]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate Mermaid ER diagram syntax.\n",
    "    \n",
    "    Args:\n",
    "        tables: Output from parse_tables()\n",
    "        relationships: Output from infer_relationships()\n",
    "    \n",
    "    Returns:\n",
    "        String containing the Mermaid diagram\n",
    "    \"\"\"\n",
    "    lines = [\"erDiagram\"]\n",
    "    \n",
    "    # Generate table blocks\n",
    "    for (schema, table_name), columns in sorted(tables.items()):\n",
    "        lines.append(f\"    {table_name} {{\")\n",
    "        for col_name, col_type in columns:\n",
    "            # Mermaid format: TYPE column_name\n",
    "            mermaid_type = col_type.upper()\n",
    "            lines.append(f\"        {mermaid_type} {col_name}\")\n",
    "        lines.append(\"    }\")\n",
    "        lines.append(\"\")  # Blank line between tables\n",
    "    \n",
    "    # Generate relationships (many fact rows to one dim row)\n",
    "    for fact_table, dim_table, col_name in relationships:\n",
    "        # ||--o{ means \"one to many\" (one dim row, many fact rows)\n",
    "        lines.append(f\"    {dim_table} ||--o{{ {fact_table} : \\\"{col_name}\\\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "print(\"Generator function defined: generate_mermaid()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Sample DDL\n",
    "\n",
    "Use the DDL from Exercises 1 and 2, plus additional dimension tables to create a complete schema.\n",
    "\n",
    "Note: We use the `public` schema with `dw_` prefixes to match the pattern from Exercises 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sample-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DDL defined (2356 characters)\n",
      "Contains: dw_dim_rider, dw_dim_route, dw_dim_mode, dw_dim_station, dw_dim_date,\n",
      "          dw_dim_payment_method, dw_dim_fare_class, dw_fact_trips\n"
     ]
    }
   ],
   "source": [
    "# ========= Sample DDL (from Exercises 1 and 2, plus supporting dims)\n",
    "\n",
    "SAMPLE_DDL = \"\"\"\n",
    "-- =============================================================\n",
    "-- DIMENSION TABLES\n",
    "-- =============================================================\n",
    "\n",
    "CREATE TABLE public.dw_dim_rider (\n",
    "    rider_sk        BIGINT IDENTITY(1,1),\n",
    "    rider_id        VARCHAR(32),\n",
    "    rider_segment   VARCHAR(16),\n",
    "    effective_from  TIMESTAMP,\n",
    "    effective_to    TIMESTAMP,\n",
    "    is_current      BOOLEAN,\n",
    "    PRIMARY KEY (rider_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_route (\n",
    "    route_sk   BIGINT IDENTITY(1,1),\n",
    "    route_id   VARCHAR(32),\n",
    "    PRIMARY KEY (route_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_mode (\n",
    "    mode_sk   BIGINT IDENTITY(1,1),\n",
    "    mode      VARCHAR(32),\n",
    "    PRIMARY KEY (mode_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_station (\n",
    "    station_sk  BIGINT IDENTITY(1,1),\n",
    "    station_id  VARCHAR(32),\n",
    "    city        VARCHAR(64),\n",
    "    province    VARCHAR(32),\n",
    "    latitude    DECIMAL(10,6),\n",
    "    longitude   DECIMAL(10,6),\n",
    "    PRIMARY KEY (station_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_date (\n",
    "    date_key     INTEGER,\n",
    "    date_actual  DATE,\n",
    "    year         SMALLINT,\n",
    "    quarter      SMALLINT,\n",
    "    month        SMALLINT,\n",
    "    day          SMALLINT,\n",
    "    day_of_week  SMALLINT,\n",
    "    is_weekend   BOOLEAN,\n",
    "    PRIMARY KEY (date_key)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_payment_method (\n",
    "    payment_method_sk  BIGINT IDENTITY(1,1),\n",
    "    payment_method     VARCHAR(32),\n",
    "    PRIMARY KEY (payment_method_sk)\n",
    ");\n",
    "\n",
    "CREATE TABLE public.dw_dim_fare_class (\n",
    "    fare_class_sk  BIGINT IDENTITY(1,1),\n",
    "    fare_class     VARCHAR(32),\n",
    "    PRIMARY KEY (fare_class_sk)\n",
    ");\n",
    "\n",
    "-- =============================================================\n",
    "-- FACT TABLES\n",
    "-- =============================================================\n",
    "\n",
    "CREATE TABLE public.dw_fact_trips (\n",
    "    trip_sk                 BIGINT IDENTITY(1,1),\n",
    "    trip_id                 VARCHAR(32),\n",
    "    rider_sk                BIGINT,\n",
    "    route_sk                BIGINT,\n",
    "    mode_sk                 BIGINT,\n",
    "    origin_station_sk       BIGINT,\n",
    "    destination_station_sk  BIGINT,\n",
    "    board_date_key          INTEGER,\n",
    "    alight_date_key         INTEGER,\n",
    "    transfers               INTEGER,\n",
    "    zones_charged           INTEGER,\n",
    "    distance_km             DECIMAL(10,2),\n",
    "    total_fare_cad          DECIMAL(12,2),\n",
    "    payment_method_sk       BIGINT,\n",
    "    fare_class_sk           BIGINT,\n",
    "    on_time_arrival         BOOLEAN,\n",
    "    service_disruption      BOOLEAN\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sample DDL defined ({len(SAMPLE_DDL)} characters)\")\n",
    "print(\"Contains: dw_dim_rider, dw_dim_route, dw_dim_mode, dw_dim_station, dw_dim_date,\")\n",
    "print(\"          dw_dim_payment_method, dw_dim_fare_class, dw_fact_trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parse-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Parse the DDL\n",
    "\n",
    "Extract tables and columns from the sample DDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "parse-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 8 tables:\n",
      "----------------------------------------\n",
      "  public.dw_dim_date: 8 columns\n",
      "  public.dw_dim_fare_class: 2 columns\n",
      "  public.dw_dim_mode: 2 columns\n",
      "  public.dw_dim_payment_method: 2 columns\n",
      "  public.dw_dim_rider: 6 columns\n",
      "  public.dw_dim_route: 2 columns\n",
      "  public.dw_dim_station: 6 columns\n",
      "  public.dw_fact_trips: 17 columns\n"
     ]
    }
   ],
   "source": [
    "tables = parse_tables(SAMPLE_DDL)\n",
    "\n",
    "print(f\"Parsed {len(tables)} tables:\")\n",
    "print(\"-\" * 40)\n",
    "for (schema, name), columns in sorted(tables.items()):\n",
    "    print(f\"  {schema}.{name}: {len(columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infer-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Infer Relationships\n",
    "\n",
    "Find fact-to-dimension relationships based on `*_sk` column naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infer-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred 5 relationships:\n",
      "----------------------------------------\n",
      "| dimension | fact | fk_column |\n",
      "| --- | --- | --- |\n",
      "| dw_dim_rider | dw_fact_trips | rider_sk |\n",
      "| dw_dim_route | dw_fact_trips | route_sk |\n",
      "| dw_dim_mode | dw_fact_trips | mode_sk |\n",
      "| dw_dim_payment_method | dw_fact_trips | payment_method_sk |\n",
      "| dw_dim_fare_class | dw_fact_trips | fare_class_sk |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relationships = infer_relationships(tables)\n",
    "\n",
    "print(f\"Inferred {len(relationships)} relationships:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Display as a table using md_table pattern\n",
    "rel_data = [\n",
    "    {\"dimension\": dim, \"fact\": fact, \"fk_column\": col}\n",
    "    for fact, dim, col in relationships\n",
    "]\n",
    "print(md_table(rel_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Generate the Mermaid Diagram\n",
    "\n",
    "Create the Mermaid ER diagram syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generate-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Mermaid ER Diagram:\n",
      "============================================================\n",
      "erDiagram\n",
      "    dw_dim_date {\n",
      "        INTEGER date_key\n",
      "        DATE date_actual\n",
      "        SMALLINT year\n",
      "        SMALLINT quarter\n",
      "        SMALLINT month\n",
      "        SMALLINT day\n",
      "        SMALLINT day_of_week\n",
      "        BOOLEAN is_weekend\n",
      "    }\n",
      "\n",
      "    dw_dim_fare_class {\n",
      "        BIGINT fare_class_sk\n",
      "        VARCHAR(32) fare_class\n",
      "    }\n",
      "\n",
      "    dw_dim_mode {\n",
      "        BIGINT mode_sk\n",
      "        VARCHAR(32) mode\n",
      "    }\n",
      "\n",
      "    dw_dim_payment_method {\n",
      "        BIGINT payment_method_sk\n",
      "        VARCHAR(32) payment_method\n",
      "    }\n",
      "\n",
      "    dw_dim_rider {\n",
      "        BIGINT rider_sk\n",
      "        VARCHAR(32) rider_id\n",
      "        VARCHAR(16) rider_segment\n",
      "        TIMESTAMP effective_from\n",
      "        TIMESTAMP effective_to\n",
      "        BOOLEAN is_current\n",
      "    }\n",
      "\n",
      "    dw_dim_route {\n",
      "        BIGINT route_sk\n",
      "        VARCHAR(32) route_id\n",
      "    }\n",
      "\n",
      "    dw_dim_station {\n",
      "        BIGINT station_sk\n",
      "        VARCHAR(32) station_id\n",
      "        VARCHAR(64) city\n",
      "        VARCHAR(32) province\n",
      "        DECIMAL(10 latitude\n",
      "        DECIMAL(10 longitude\n",
      "    }\n",
      "\n",
      "    dw_fact_trips {\n",
      "        BIGINT trip_sk\n",
      "        VARCHAR(32) trip_id\n",
      "        BIGINT rider_sk\n",
      "        BIGINT route_sk\n",
      "        BIGINT mode_sk\n",
      "        BIGINT origin_station_sk\n",
      "        BIGINT destination_station_sk\n",
      "        INTEGER board_date_key\n",
      "        INTEGER alight_date_key\n",
      "        INTEGER transfers\n",
      "        INTEGER zones_charged\n",
      "        DECIMAL(10 distance_km\n",
      "        DECIMAL(12 total_fare_cad\n",
      "        BIGINT payment_method_sk\n",
      "        BIGINT fare_class_sk\n",
      "        BOOLEAN on_time_arrival\n",
      "        BOOLEAN service_disruption\n",
      "    }\n",
      "\n",
      "    dw_dim_rider ||--o{ dw_fact_trips : \"rider_sk\"\n",
      "    dw_dim_route ||--o{ dw_fact_trips : \"route_sk\"\n",
      "    dw_dim_mode ||--o{ dw_fact_trips : \"mode_sk\"\n",
      "    dw_dim_payment_method ||--o{ dw_fact_trips : \"payment_method_sk\"\n",
      "    dw_dim_fare_class ||--o{ dw_fact_trips : \"fare_class_sk\"\n"
     ]
    }
   ],
   "source": [
    "mermaid_diagram = generate_mermaid(tables, relationships)\n",
    "\n",
    "print(\"Generated Mermaid ER Diagram:\")\n",
    "print(\"=\" * 60)\n",
    "print(mermaid_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Save to File\n",
    "\n",
    "Write the diagram to a `.mmd` file for use in documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "save-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagram saved to: /workspace/schema.mmd\n",
      "\n",
      "Next steps:\n",
      "  1. Preview at https://mermaid.live\n",
      "  2. Or use VS Code with Mermaid extension\n",
      "  3. Or render to PNG: mmdc -i schema.mmd -o schema.png\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(OUTPUT_MERMAID)\n",
    "output_path.write_text(mermaid_diagram, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Diagram saved to: {output_path.absolute()}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Preview at https://mermaid.live\")\n",
    "print(\"  2. Or use VS Code with Mermaid extension\")\n",
    "print(\"  3. Or render to PNG: mmdc -i schema.mmd -o schema.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Display in Notebook\n",
    "\n",
    "Display the Mermaid code for easy copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "display-001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "erDiagram\n",
       "    dw_dim_date {\n",
       "        INTEGER date_key\n",
       "        DATE date_actual\n",
       "        SMALLINT year\n",
       "        SMALLINT quarter\n",
       "        SMALLINT month\n",
       "        SMALLINT day\n",
       "        SMALLINT day_of_week\n",
       "        BOOLEAN is_weekend\n",
       "    }\n",
       "\n",
       "    dw_dim_fare_class {\n",
       "        BIGINT fare_class_sk\n",
       "        VARCHAR(32) fare_class\n",
       "    }\n",
       "\n",
       "    dw_dim_mode {\n",
       "        BIGINT mode_sk\n",
       "        VARCHAR(32) mode\n",
       "    }\n",
       "\n",
       "    dw_dim_payment_method {\n",
       "        BIGINT payment_method_sk\n",
       "        VARCHAR(32) payment_method\n",
       "    }\n",
       "\n",
       "    dw_dim_rider {\n",
       "        BIGINT rider_sk\n",
       "        VARCHAR(32) rider_id\n",
       "        VARCHAR(16) rider_segment\n",
       "        TIMESTAMP effective_from\n",
       "        TIMESTAMP effective_to\n",
       "        BOOLEAN is_current\n",
       "    }\n",
       "\n",
       "    dw_dim_route {\n",
       "        BIGINT route_sk\n",
       "        VARCHAR(32) route_id\n",
       "    }\n",
       "\n",
       "    dw_dim_station {\n",
       "        BIGINT station_sk\n",
       "        VARCHAR(32) station_id\n",
       "        VARCHAR(64) city\n",
       "        VARCHAR(32) province\n",
       "        DECIMAL(10 latitude\n",
       "        DECIMAL(10 longitude\n",
       "    }\n",
       "\n",
       "    dw_fact_trips {\n",
       "        BIGINT trip_sk\n",
       "        VARCHAR(32) trip_id\n",
       "        BIGINT rider_sk\n",
       "        BIGINT route_sk\n",
       "        BIGINT mode_sk\n",
       "        BIGINT origin_station_sk\n",
       "        BIGINT destination_station_sk\n",
       "        INTEGER board_date_key\n",
       "        INTEGER alight_date_key\n",
       "        INTEGER transfers\n",
       "        INTEGER zones_charged\n",
       "        DECIMAL(10 distance_km\n",
       "        DECIMAL(12 total_fare_cad\n",
       "        BIGINT payment_method_sk\n",
       "        BIGINT fare_class_sk\n",
       "        BOOLEAN on_time_arrival\n",
       "        BOOLEAN service_disruption\n",
       "    }\n",
       "\n",
       "    dw_dim_rider ||--o{ dw_fact_trips : \"rider_sk\"\n",
       "    dw_dim_route ||--o{ dw_fact_trips : \"route_sk\"\n",
       "    dw_dim_mode ||--o{ dw_fact_trips : \"mode_sk\"\n",
       "    dw_dim_payment_method ||--o{ dw_fact_trips : \"payment_method_sk\"\n",
       "    dw_dim_fare_class ||--o{ dw_fact_trips : \"fare_class_sk\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the raw Mermaid code in a code block for easy copying\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(f\"\"\"```mermaid\n",
    "{mermaid_diagram}\n",
    "```\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "report-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Generate a Report Summary\n",
    "\n",
    "This shows how you might include the diagram in a markdown report, similar to the final project's reporting section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "report-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to: /workspace/schema_report.md\n"
     ]
    }
   ],
   "source": [
    "# Generate a report like the project solution does\n",
    "report_path = Path(BASE_DIR) / \"schema_report.md\"\n",
    "\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Schema Design Report\\n\\n\")\n",
    "    f.write(f\"_Generated: {datetime.utcnow().isoformat()}Z_\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Schema Diagram (Mermaid)\\n\\n\")\n",
    "    f.write(\"```mermaid\\n\" + mermaid_diagram + \"\\n```\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Tables Summary\\n\\n\")\n",
    "    table_summary = [\n",
    "        {\"schema\": schema, \"table\": name, \"columns\": len(cols)}\n",
    "        for (schema, name), cols in sorted(tables.items())\n",
    "    ]\n",
    "    f.write(md_table(table_summary))\n",
    "    \n",
    "    f.write(\"\\n## Relationships\\n\\n\")\n",
    "    f.write(md_table(rel_data))\n",
    "\n",
    "print(f\"Report saved to: {report_path.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
