{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f88741-9dfa-4e8f-b14d-4931e1aa557a",
   "metadata": {},
   "source": [
    "# Lesson 1 - Exercise 1 (Python): Connect to PostgreSQL and Preview Trips\n",
    "\n",
    "## Goal\n",
    "\n",
    "Connect to a PostgreSQL source containing a `raw_trips` table and\n",
    "produce an initial data profile to understand the schema you'll stage\n",
    "into Redshift later.\n",
    "\n",
    "## What to build\n",
    "\n",
    "A Jupyter notebook that:\n",
    "\n",
    "1.  Connects to Postgres via `SQLAlchemy`/`psycopg2`.\n",
    "\n",
    "2.  Runs SQL queries to:\n",
    "\n",
    "    -   Count rows.\n",
    "    -   Sample 10 rows.\n",
    "    -   Compute quick null/unique stats for key columns.\n",
    "\n",
    "3.  Writes a CSV preview `/tmp/trips_preview.csv` and prints a short\n",
    "    profile to stdout.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0001-4000-a001-000000000001",
   "metadata": {},
   "source": [
    "### Step 1: Imports and Configuration\n",
    "\n",
    "Load required libraries and set up connection parameters from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5-0001-4000-b001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- Configuration (from environment variables or defaults) ---\n",
    "PG_HOST = os.environ.get(\"PG_HOST\", \"localhost\")\n",
    "PG_PORT = os.environ.get(\"PG_PORT\", \"5432\")\n",
    "PG_DB = os.environ.get(\"PG_DB\", \"transit\")\n",
    "PG_USER = os.environ.get(\"PG_USER\", \"postgres\")\n",
    "PG_PASSWORD = os.environ.get(\"PG_PASSWORD\", \"postgres\")\n",
    "\n",
    "# Build connection URI\n",
    "PG_URI = os.environ.get(\n",
    "    \"PG_URI\", \n",
    "    f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    ")\n",
    "\n",
    "OUT_FILE = \"/tmp/trips_preview.csv\"\n",
    "\n",
    "print(f\"PostgreSQL Host: {PG_HOST}:{PG_PORT}\")\n",
    "print(f\"Database: {PG_DB}\")\n",
    "print(f\"Output file: {OUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6-0001-4000-c001-000000000001",
   "metadata": {},
   "source": [
    "### Step 2: Connect to PostgreSQL\n",
    "\n",
    "Establish a connection to the PostgreSQL database using SQLAlchemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-0001-4000-d001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(PG_URI)\n",
    "\n",
    "# Test the connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"Successfully connected to PostgreSQL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0001-4000-e001-000000000001",
   "metadata": {},
   "source": [
    "### Step 3: Count Total Rows\n",
    "\n",
    "Get the total number of rows in the `raw_trips` table to understand the data volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-0001-4000-e001-000000000002",
   "metadata": {},
   "source": [
    "**TODO**: Write a SQL query to count the total number of rows in the `raw_trips` table. Execute the query and store the result in `row_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-0001-4000-f001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_COUNT = \"\"  # TODO: Write your SQL query here\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # TODO: Execute the query and extract the row count\n",
    "    row_count = None\n",
    "\n",
    "print(f\"Total rows in raw_trips: {row_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0001-4000-a002-000000000001",
   "metadata": {},
   "source": [
    "### Step 4: Sample Rows from the Table\n",
    "\n",
    "Pull a sample of rows to understand the data structure and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-0001-4000-a002-000000000002",
   "metadata": {},
   "source": [
    "**TODO**: Write a SQL query to randomly sample 10 rows from the `raw_trips` table. The query should select all columns listed below. Use `ORDER BY RANDOM()` to randomize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1-0001-4000-b002-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to select:\n",
    "# trip_id, rider_id, route_id, mode, origin_station_id, destination_station_id,\n",
    "# board_datetime, alight_datetime, country, province, fare_class, payment_method,\n",
    "# transfers, zones_charged, distance_km, base_fare_cad, discount_rate, discount_amount_cad,\n",
    "# yvr_addfare_cad, total_fare_cad, on_time_arrival, service_disruption, polyline_stations\n",
    "\n",
    "SQL_SAMPLE = \"\"\"\n",
    "-- TODO: Write your SQL query here\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    sample_df = pd.read_sql(text(SQL_SAMPLE), conn)\n",
    "\n",
    "print(f\"Sampled {len(sample_df)} rows\")\n",
    "print(\"-\" * 40)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2-0001-4000-c002-000000000001",
   "metadata": {},
   "source": [
    "### Step 5: Profile Key Columns\n",
    "\n",
    "Compute null percentages and unique counts for the key columns we'll need for staging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2-0001-4000-c002-000000000002",
   "metadata": {},
   "source": [
    "**TODO**: Build a profile for the key columns listed below. For each column, compute:\n",
    "- `dtype`: The pandas data type of the column\n",
    "- `null_pct`: The percentage of null values (rounded to 2 decimal places)\n",
    "- `n_unique`: The number of unique non-null values\n",
    "- `sample_value`: A sample non-null value from the column\n",
    "\n",
    "Store the results in `profile_data` as a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3-0001-4000-d002-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key columns for profiling\n",
    "key_columns = [\"trip_id\", \"rider_id\", \"route_id\", \"board_datetime\", \"alight_datetime\"]\n",
    "\n",
    "# Build profile\n",
    "profile_data = []\n",
    "for col in key_columns:\n",
    "    if col in sample_df.columns:\n",
    "        series = sample_df[col]\n",
    "        # TODO: Build a dictionary with keys: column, dtype, null_pct, n_unique, sample_value\n",
    "        profile_data.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": None,      # TODO: Get the dtype as a string\n",
    "            \"null_pct\": None,   # TODO: Calculate null percentage (0-100)\n",
    "            \"n_unique\": None,   # TODO: Count unique non-null values\n",
    "            \"sample_value\": None  # TODO: Get a sample non-null value\n",
    "        })\n",
    "    else:\n",
    "        profile_data.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": \"MISSING\",\n",
    "            \"null_pct\": None,\n",
    "            \"n_unique\": None,\n",
    "            \"sample_value\": None\n",
    "        })\n",
    "\n",
    "profile_df = pd.DataFrame(profile_data)\n",
    "\n",
    "print(\"Key Column Profile (from sample):\")\n",
    "print(\"-\" * 40)\n",
    "display(profile_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4-0001-4000-e002-000000000001",
   "metadata": {},
   "source": [
    "### Step 6: Check All Column Data Types\n",
    "\n",
    "Review the data types of all columns to plan the staging table DDL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4-0001-4000-e002-000000000002",
   "metadata": {},
   "source": [
    "**TODO**: Loop through all columns in `sample_df` and print each column name, its data type, and the count of null values. Format the output so columns align nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5-0001-4000-f002-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Column Data Types:\")\n",
    "print(\"-\" * 40)\n",
    "# TODO: Loop through sample_df.dtypes and print column info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6-0001-4000-a003-000000000001",
   "metadata": {},
   "source": [
    "### Step 7: Write Sample to CSV\n",
    "\n",
    "Save the sample trips to a CSV file for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6-0001-4000-a003-000000000002",
   "metadata": {},
   "source": [
    "**TODO**: Write `sample_df` to the CSV file specified by `OUT_FILE`. Then read it back to verify the write was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7-0001-4000-b003-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write sample_df to CSV (without the index)\n",
    "\n",
    "\n",
    "# TODO: Read the file back to verify\n",
    "verify_df = None\n",
    "\n",
    "print(f\"Wrote {len(sample_df)} rows to {OUT_FILE}\")\n",
    "print(f\"Verified: {len(verify_df)} rows, {len(verify_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8-0001-4000-c003-000000000001",
   "metadata": {},
   "source": [
    "### Step 8: Clean Up\n",
    "\n",
    "Dispose of the SQLAlchemy engine to close connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9-0001-4000-d003-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()\n",
    "print(\"PostgreSQL connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e3bda-0001-4000-e003-000000000001",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, you:\n",
    "\n",
    "1. Connected to PostgreSQL using SQLAlchemy\n",
    "2. Counted total rows to understand data volume\n",
    "3. Sampled rows to explore the data structure\n",
    "4. Profiled key columns (trip_id, rider_id, route_id, timestamps)\n",
    "5. Reviewed all column data types for staging planning\n",
    "6. Exported a preview CSV for reference\n",
    "\n",
    "These patterns (env-driven config, bounded reads, quick stats, CSV outputs) are exactly what you'll reuse when building **ETL pipelines** in later lessons and for the final **e-commerce project**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
