{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Lesson 3: Exercise 1 Solution - Extract and Transform Trips from PostgreSQL\n",
    "\n",
    "## Goal\n",
    "\n",
    "Extract trips data from PostgreSQL and transform it into a **staging format** ready for warehouse loading. This is the first step in our ETL pipeline.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You should have completed:\n",
    "- **Lesson 1, Exercise 1**: Connected to PostgreSQL and previewed the `raw_trips` table\n",
    "- **Lesson 2, Exercise 1**: Designed the `dw_dim_rider` table in Redshift\n",
    "\n",
    "## What You Will Build\n",
    "\n",
    "A Pandas-based ETL script that:\n",
    "\n",
    "1. Connects to PostgreSQL and extracts trips data\n",
    "2. Cleans and standardizes fields (whitespace, nulls, data types)\n",
    "3. Validates the transformation\n",
    "4. Outputs to staging format (CSV/Parquet)\n",
    "\n",
    "\n",
    "### Acceptance Criteria\n",
    "\n",
    "- Trips data is extracted from PostgreSQL `raw_trips` table\n",
    "- Data is cleaned and transformed\n",
    "- Output matches the `stg_trips_raw` schema structure\n",
    "- Row counts are preserved (no data loss)\n",
    "- Output file is created successfully\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77220a-4b1d-400f-a4be-9ba315d54c20",
   "metadata": {},
   "source": [
    "## Lesson 3 Exercise 1: Extract and Transform Trips from PostgreSQL Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "Run this cell first to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "   - pandas version: 2.3.1\n",
      "   - numpy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# ========= Imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"   - pandas version: {pd.__version__}\")\n",
    "print(f\"   - numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "**Important:** These credentials match the `populate-postgres.py` script from Lesson 1. Update only if your environment differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "   - PostgreSQL: localhost:5432/postgres\n",
      "   - User: temp\n",
      "   - Output CSV: /tmp/stg_trips_raw.csv\n",
      "   - Output Parquet: /tmp/stg_trips_raw.parquet\n"
     ]
    }
   ],
   "source": [
    "# ========= PostgreSQL Configuration ==========\n",
    "# These match the populate-postgres.py script from Lesson 1.\n",
    "# Only change if your environment is different.\n",
    "\n",
    "PG_HOST = \"localhost\"      # Database host\n",
    "PG_PORT = \"5432\"           # Database port\n",
    "PG_DB = \"postgres\"         # Database name (populate script uses 'postgres')\n",
    "PG_USER = \"temp\"           # User from populate-postgres.py\n",
    "PG_PASSWORD = \"temp\"       # Password from populate-postgres.py\n",
    "\n",
    "# Build connection URI\n",
    "PG_URI = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_STAGING_CSV = \"/tmp/stg_trips_raw.csv\"\n",
    "OUTPUT_STAGING_PARQUET = \"/tmp/stg_trips_raw.parquet\"\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"   - PostgreSQL: {PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "print(f\"   - User: {PG_USER}\")\n",
    "print(f\"   - Output CSV: {OUTPUT_STAGING_CSV}\")\n",
    "print(f\"   - Output Parquet: {OUTPUT_STAGING_PARQUET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify Database Setup\n",
    "\n",
    "This cell verifies that the `raw_trips` table exists and has data. If verification fails, you need to run the `populate-postgres.py` script from Lesson 1:\n",
    "\n",
    "```python\n",
    "!python populate-postgres.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verify-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying PostgreSQL setup...\n",
      "--------------------------------------------------\n",
      "Connected to PostgreSQL (localhost:5432/postgres)\n",
      "Table 'raw_trips' exists with 2,500 rows\n",
      "\n",
      "Sample data:\n",
      "   ('T100000', 'R33247', Decimal('3.32'))\n",
      "   ('T100001', 'R43159', Decimal('3.17'))\n",
      "   ('T100002', 'R18110', Decimal('2.12'))\n",
      "\n",
      "Verification PASSED - ready to proceed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= Verify Database Setup ==========\n",
    "# This checks that raw_trips exists and has data from Lesson 1.\n",
    "\n",
    "def verify_postgres_setup():\n",
    "    \"\"\"Verify PostgreSQL has the raw_trips table with data.\"\"\"\n",
    "    print(\"Verifying PostgreSQL setup...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine(PG_URI)\n",
    "        with engine.connect() as conn:\n",
    "            # Test connection\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "            print(f\"Connected to PostgreSQL ({PG_HOST}:{PG_PORT}/{PG_DB})\")\n",
    "            \n",
    "            # Check if raw_trips exists\n",
    "            result = conn.execute(text(\n",
    "                \"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'raw_trips')\"\n",
    "            ))\n",
    "            table_exists = result.scalar()\n",
    "            \n",
    "            if not table_exists:\n",
    "                print(\"\\n*** ERROR: Table 'raw_trips' does not exist! ***\")\n",
    "                print(\"\\nPlease run the populate script from Lesson 1:\")\n",
    "                print(\"   python populate-postgres.py\")\n",
    "                engine.dispose()\n",
    "                return False\n",
    "            \n",
    "            # Check row count\n",
    "            result = conn.execute(text(\"SELECT COUNT(*) FROM raw_trips\"))\n",
    "            count = result.scalar()\n",
    "            \n",
    "            if count == 0:\n",
    "                print(\"\\n*** ERROR: Table 'raw_trips' is empty! ***\")\n",
    "                print(\"\\nPlease run the populate script from Lesson 1:\")\n",
    "                print(\"   python populate-postgres.py\")\n",
    "                engine.dispose()\n",
    "                return False\n",
    "            \n",
    "            print(f\"Table 'raw_trips' exists with {count:,} rows\")\n",
    "            \n",
    "            # Show sample\n",
    "            result = conn.execute(text(\"SELECT trip_id, rider_id, total_fare_cad FROM raw_trips LIMIT 3\"))\n",
    "            print(\"\\nSample data:\")\n",
    "            for row in result:\n",
    "                print(f\"   {row}\")\n",
    "        \n",
    "        engine.dispose()\n",
    "        print(\"\\nVerification PASSED - ready to proceed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n*** ERROR: Could not connect to PostgreSQL! ***\")\n",
    "        print(f\"Details: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"  1. Is PostgreSQL running?\")\n",
    "        print(\"  2. Check credentials in the Configuration cell above\")\n",
    "        print(\"  3. Run: python populate-postgres.py\")\n",
    "        return False\n",
    "\n",
    "# Run verification\n",
    "verify_postgres_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colspec-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Column Specification\n",
    "\n",
    "Define the expected columns and their types for the staging table. This matches the structure we'll use in Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colspec-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column spec defined: 23 columns\n",
      "\n",
      "Column breakdown:\n",
      "   - String columns: 11\n",
      "   - Timestamp columns: 2\n",
      "   - Integer columns: 2\n",
      "   - Float columns: 6\n",
      "   - Boolean columns: 2\n"
     ]
    }
   ],
   "source": [
    "# ========= Column specs for staging (name, kind)\n",
    "# kind: 's' = string, 'ts' = timestamp, 'i' = integer, 'f' = float, 'b' = boolean\n",
    "\n",
    "TRIPS_COLSPEC = [\n",
    "    ('trip_id', 's'),\n",
    "    ('rider_id', 's'),\n",
    "    ('route_id', 's'),\n",
    "    ('mode', 's'),\n",
    "    ('origin_station_id', 's'),\n",
    "    ('destination_station_id', 's'),\n",
    "    ('board_datetime', 'ts'),\n",
    "    ('alight_datetime', 'ts'),\n",
    "    ('country', 's'),\n",
    "    ('province', 's'),\n",
    "    ('fare_class', 's'),\n",
    "    ('payment_method', 's'),\n",
    "    ('transfers', 'i'),\n",
    "    ('zones_charged', 'i'),\n",
    "    ('distance_km', 'f'),\n",
    "    ('base_fare_cad', 'f'),\n",
    "    ('discount_rate', 'f'),\n",
    "    ('discount_amount_cad', 'f'),\n",
    "    ('yvr_addfare_cad', 'f'),\n",
    "    ('total_fare_cad', 'f'),\n",
    "    ('on_time_arrival', 'b'),\n",
    "    ('service_disruption', 'b'),\n",
    "    ('polyline_stations', 's'),\n",
    "]\n",
    "\n",
    "print(f\"Column spec defined: {len(TRIPS_COLSPEC)} columns\")\n",
    "print(\"\\nColumn breakdown:\")\n",
    "print(f\"   - String columns: {sum(1 for _, k in TRIPS_COLSPEC if k == 's')}\")\n",
    "print(f\"   - Timestamp columns: {sum(1 for _, k in TRIPS_COLSPEC if k == 'ts')}\")\n",
    "print(f\"   - Integer columns: {sum(1 for _, k in TRIPS_COLSPEC if k == 'i')}\")\n",
    "print(f\"   - Float columns: {sum(1 for _, k in TRIPS_COLSPEC if k == 'f')}\")\n",
    "print(f\"   - Boolean columns: {sum(1 for _, k in TRIPS_COLSPEC if k == 'b')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions\n",
    "\n",
    "These functions are adapted from the project solution for cleaning and transforming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helpers-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined: trim_df(), validate_columns()\n"
     ]
    }
   ],
   "source": [
    "# ========= Helper Functions (from project solution)\n",
    "\n",
    "def trim_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize text fields (strip whitespace) and handle NaN values properly.\n",
    "    \n",
    "    This is the same helper used in the final project for cleaning extracted data.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with potentially messy string fields\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned DataFrame with stripped strings and proper NaN handling\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    for c in df.select_dtypes(include=['object']).columns:\n",
    "        # Convert to string and strip whitespace\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        # Replace 'nan', 'None', and empty strings with actual NaN\n",
    "        df[c] = df[c].mask(df[c].isin(['nan', 'None', 'NaN', '']), np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_columns(df: pd.DataFrame, colspec: List[Tuple[str, str]]) -> dict:\n",
    "    \"\"\"\n",
    "    Validate that DataFrame columns match the expected spec.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to validate\n",
    "        colspec: List of (column_name, type_code) tuples\n",
    "    \n",
    "    Returns:\n",
    "        Dict with validation results\n",
    "    \"\"\"\n",
    "    expected_cols = {c for c, _ in colspec}\n",
    "    actual_cols = set(df.columns)\n",
    "    \n",
    "    return {\n",
    "        'missing': expected_cols - actual_cols,\n",
    "        'extra': actual_cols - expected_cols,\n",
    "        'matched': expected_cols & actual_cols,\n",
    "        'valid': expected_cols == actual_cols\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Helper functions defined: trim_df(), validate_columns()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connect-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Connect to PostgreSQL\n",
    "\n",
    "Establish a connection to the PostgreSQL database using SQLAlchemy (same pattern as Lesson 1, Exercise 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "connect-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Connecting to PostgreSQL...\n",
      "--------------------------------------------------\n",
      "Successfully connected to PostgreSQL!\n",
      "Total rows in raw_trips: 2,500\n"
     ]
    }
   ],
   "source": [
    "# ========= STEP 1: Connect to PostgreSQL\n",
    "print(\"Step 1: Connecting to PostgreSQL...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "engine = create_engine(PG_URI)\n",
    "\n",
    "# Test the connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"Successfully connected to PostgreSQL!\")\n",
    "    \n",
    "    # Get row count\n",
    "    count_result = conn.execute(text(\"SELECT COUNT(*) FROM raw_trips\"))\n",
    "    total_rows = count_result.scalar()\n",
    "    print(f\"Total rows in raw_trips: {total_rows:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Extract Data from PostgreSQL\n",
    "\n",
    "Pull all trips data from the `raw_trips` table. In production ETL, you might add filters for incremental loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extract-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting trips data from PostgreSQL...\n",
      "--------------------------------------------------\n",
      "Extracted 2,500 rows\n",
      "Columns: 23\n",
      "\n",
      "Sample data (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>origin_station_id</th>\n",
       "      <th>destination_station_id</th>\n",
       "      <th>board_datetime</th>\n",
       "      <th>alight_datetime</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>...</th>\n",
       "      <th>zones_charged</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>base_fare_cad</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_amount_cad</th>\n",
       "      <th>yvr_addfare_cad</th>\n",
       "      <th>total_fare_cad</th>\n",
       "      <th>on_time_arrival</th>\n",
       "      <th>service_disruption</th>\n",
       "      <th>polyline_stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T100000</td>\n",
       "      <td>R33247</td>\n",
       "      <td>R111</td>\n",
       "      <td>bus</td>\n",
       "      <td>S021</td>\n",
       "      <td>S004</td>\n",
       "      <td>2024-01-31 10:45:08</td>\n",
       "      <td>2024-01-31 11:12:09</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.26</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S001|S025|S009|S008|S009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T100001</td>\n",
       "      <td>R43159</td>\n",
       "      <td>R033</td>\n",
       "      <td>bus</td>\n",
       "      <td>S005</td>\n",
       "      <td>S025</td>\n",
       "      <td>2024-08-08 00:16:41</td>\n",
       "      <td>2024-08-08 00:44:35</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11.66</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S004|S023|S025|S030|S018|S003|S020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T100002</td>\n",
       "      <td>R18110</td>\n",
       "      <td>R001</td>\n",
       "      <td>bus</td>\n",
       "      <td>S014</td>\n",
       "      <td>S002</td>\n",
       "      <td>2024-05-28 02:42:12</td>\n",
       "      <td>2024-05-28 03:14:48</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.35</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>S001|S004|S008|S009|S018|S021|S001|S019|S007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id rider_id route_id mode origin_station_id destination_station_id  \\\n",
       "0  T100000   R33247     R111  bus              S021                   S004   \n",
       "1  T100001   R43159     R033  bus              S005                   S025   \n",
       "2  T100002   R18110     R001  bus              S014                   S002   \n",
       "\n",
       "       board_datetime     alight_datetime country province  ... zones_charged  \\\n",
       "0 2024-01-31 10:45:08 2024-01-31 11:12:09      CA       BC  ...             1   \n",
       "1 2024-08-08 00:16:41 2024-08-08 00:44:35      CA       BC  ...             1   \n",
       "2 2024-05-28 02:42:12 2024-05-28 03:14:48      CA       BC  ...             1   \n",
       "\n",
       "  distance_km  base_fare_cad  discount_rate  discount_amount_cad  \\\n",
       "0        7.26           3.32           0.00                  0.0   \n",
       "1       11.66           3.17           0.00                  0.0   \n",
       "2       15.35           3.12           0.32                  1.0   \n",
       "\n",
       "   yvr_addfare_cad  total_fare_cad  on_time_arrival  service_disruption  \\\n",
       "0              0.0            3.32             True               False   \n",
       "1              0.0            3.17             True               False   \n",
       "2              0.0            2.12            False               False   \n",
       "\n",
       "                              polyline_stations  \n",
       "0                      S001|S025|S009|S008|S009  \n",
       "1            S004|S023|S025|S030|S018|S003|S020  \n",
       "2  S001|S004|S008|S009|S018|S021|S001|S019|S007  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========= STEP 2: Extract from PostgreSQL\n",
    "print(\"Step 2: Extracting trips data from PostgreSQL...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# SQL to extract all trips\n",
    "# In production, you might add WHERE clauses for incremental loads\n",
    "SQL_EXTRACT = \"\"\"\n",
    "SELECT \n",
    "    trip_id,\n",
    "    rider_id,\n",
    "    route_id,\n",
    "    mode,\n",
    "    origin_station_id,\n",
    "    destination_station_id,\n",
    "    board_datetime,\n",
    "    alight_datetime,\n",
    "    country,\n",
    "    province,\n",
    "    fare_class,\n",
    "    payment_method,\n",
    "    transfers,\n",
    "    zones_charged,\n",
    "    distance_km,\n",
    "    base_fare_cad,\n",
    "    discount_rate,\n",
    "    discount_amount_cad,\n",
    "    yvr_addfare_cad,\n",
    "    total_fare_cad,\n",
    "    on_time_arrival,\n",
    "    service_disruption,\n",
    "    polyline_stations\n",
    "FROM raw_trips\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    trips_raw = pd.read_sql(text(SQL_EXTRACT), conn)\n",
    "\n",
    "print(f\"Extracted {len(trips_raw):,} rows\")\n",
    "print(f\"Columns: {len(trips_raw.columns)}\")\n",
    "print(f\"\\nSample data (first 3 rows):\")\n",
    "display(trips_raw.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transform-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Transform and Clean Data\n",
    "\n",
    "Apply transformations to prepare the data for staging:\n",
    "- Strip whitespace from string fields\n",
    "- Standardize NULL representations\n",
    "- Parse timestamps\n",
    "- Ensure proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transform-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Transforming and cleaning data...\n",
      "--------------------------------------------------\n",
      "Applied trim_df() - whitespace stripped, NaN standardized\n",
      "\n",
      "Transformation complete!\n",
      "   - Rows: 2,500\n",
      "   - Columns: 23\n"
     ]
    }
   ],
   "source": [
    "# ========= STEP 3: Transform and clean\n",
    "print(\"Step 3: Transforming and cleaning data...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Apply string cleaning\n",
    "trips_clean = trim_df(trips_raw)\n",
    "print(\"Applied trim_df() - whitespace stripped, NaN standardized\")\n",
    "\n",
    "# Parse timestamp columns (if not already datetime)\n",
    "timestamp_cols = [c for c, k in TRIPS_COLSPEC if k == 'ts']\n",
    "for col in timestamp_cols:\n",
    "    if col in trips_clean.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(trips_clean[col]):\n",
    "            trips_clean[col] = pd.to_datetime(trips_clean[col], errors='coerce')\n",
    "            print(f\"   Parsed timestamp: {col}\")\n",
    "\n",
    "# Ensure boolean columns are proper booleans\n",
    "boolean_cols = [c for c, k in TRIPS_COLSPEC if k == 'b']\n",
    "for col in boolean_cols:\n",
    "    if col in trips_clean.columns:\n",
    "        # Handle various boolean representations\n",
    "        if trips_clean[col].dtype == 'object':\n",
    "            trips_clean[col] = trips_clean[col].map(\n",
    "                lambda x: True if str(x).lower() in ('true', 't', '1', 'yes') \n",
    "                          else (False if str(x).lower() in ('false', 'f', '0', 'no') else None)\n",
    "            )\n",
    "            print(f\"   Converted boolean: {col}\")\n",
    "\n",
    "# Ensure numeric columns are proper types\n",
    "float_cols = [c for c, k in TRIPS_COLSPEC if k == 'f']\n",
    "for col in float_cols:\n",
    "    if col in trips_clean.columns:\n",
    "        trips_clean[col] = pd.to_numeric(trips_clean[col], errors='coerce')\n",
    "\n",
    "int_cols = [c for c, k in TRIPS_COLSPEC if k == 'i']\n",
    "for col in int_cols:\n",
    "    if col in trips_clean.columns:\n",
    "        trips_clean[col] = pd.to_numeric(trips_clean[col], errors='coerce').astype('Int64')\n",
    "\n",
    "print(f\"\\nTransformation complete!\")\n",
    "print(f\"   - Rows: {len(trips_clean):,}\")\n",
    "print(f\"   - Columns: {len(trips_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transform-002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data types after transformation\n",
    "print(\"Data types after transformation:\")\n",
    "print(\"-\" * 50)\n",
    "print(trips_clean.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Validate the Transformation\n",
    "\n",
    "Before outputting, verify that:\n",
    "- All expected columns are present\n",
    "- Row counts match (no data loss)\n",
    "- Key fields have no unexpected nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "validate-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Validating transformation...\n",
      "--------------------------------------------------\n",
      "Column validation: PASSED\n",
      "\n",
      "Row count check:\n",
      "   Source rows: 2,500\n",
      "   Output rows: 2,500\n",
      "   Match: YES\n",
      "\n",
      "Null check for key fields:\n",
      "   trip_id: 0 nulls (0.00%)\n",
      "   rider_id: 0 nulls (0.00%)\n",
      "   route_id: 0 nulls (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# ========= STEP 4: Validate\n",
    "print(\"Step 4: Validating transformation...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check column alignment\n",
    "validation = validate_columns(trips_clean, TRIPS_COLSPEC)\n",
    "\n",
    "if validation['valid']:\n",
    "    print(\"Column validation: PASSED\")\n",
    "else:\n",
    "    print(\"Column validation: ISSUES FOUND\")\n",
    "    if validation['missing']:\n",
    "        print(f\"   Missing columns: {validation['missing']}\")\n",
    "    if validation['extra']:\n",
    "        print(f\"   Extra columns: {validation['extra']}\")\n",
    "\n",
    "# Check row counts\n",
    "print(f\"\\nRow count check:\")\n",
    "print(f\"   Source rows: {len(trips_raw):,}\")\n",
    "print(f\"   Output rows: {len(trips_clean):,}\")\n",
    "print(f\"   Match: {'YES' if len(trips_raw) == len(trips_clean) else 'NO - DATA LOSS!'}\")\n",
    "\n",
    "# Check for nulls in key fields\n",
    "key_fields = ['trip_id', 'rider_id', 'route_id']\n",
    "print(f\"\\nNull check for key fields:\")\n",
    "for field in key_fields:\n",
    "    null_count = trips_clean[field].isna().sum()\n",
    "    print(f\"   {field}: {null_count} nulls ({null_count/len(trips_clean)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "validate-002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for key measures:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_km</th>\n",
       "      <th>total_fare_cad</th>\n",
       "      <th>transfers</th>\n",
       "      <th>zones_charged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.854608</td>\n",
       "      <td>3.028128</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>1.1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.058530</td>\n",
       "      <td>0.941073</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>0.344549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.637500</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.110000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.922500</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.810000</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_km  total_fare_cad  transfers  zones_charged\n",
       "count  2500.000000     2500.000000     2500.0         2500.0\n",
       "mean     10.854608        3.028128     0.3868         1.1376\n",
       "std       5.058530        0.941073     0.5971       0.344549\n",
       "min       0.800000        1.860000        0.0            1.0\n",
       "25%       7.637500        2.170000        0.0            1.0\n",
       "50%      10.110000        3.130000        0.0            1.0\n",
       "75%      12.922500        3.190000        1.0            1.0\n",
       "max      31.810000        9.580000        2.0            2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics for numeric fields\n",
    "print(\"Summary statistics for key measures:\")\n",
    "print(\"-\" * 50)\n",
    "display(trips_clean[['distance_km', 'total_fare_cad', 'transfers', 'zones_charged']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Output to Staging Format\n",
    "\n",
    "Save the transformed data in formats suitable for warehouse loading:\n",
    "- **CSV**: Human-readable, compatible with Redshift COPY\n",
    "- **Parquet**: Compressed, columnar format for efficient loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "output-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Outputting to staging format...\n",
      "--------------------------------------------------\n",
      "CSV saved: /tmp/stg_trips_raw.csv\n",
      "   Size: 449.1 KB\n",
      "\n",
      "Parquet output skipped (pyarrow not installed).\n",
      "   To enable: pip install pyarrow\n",
      "   CSV output is sufficient for this exercise.\n"
     ]
    }
   ],
   "source": [
    "# ========= STEP 5: Output to staging format\n",
    "print(\"Step 5: Outputting to staging format...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Select only the columns defined in the spec (in order)\n",
    "output_cols = [c for c, _ in TRIPS_COLSPEC]\n",
    "trips_staging = trips_clean[output_cols]\n",
    "\n",
    "# Output to CSV\n",
    "trips_staging.to_csv(OUTPUT_STAGING_CSV, index=False)\n",
    "csv_size = os.path.getsize(OUTPUT_STAGING_CSV) / 1024  # KB\n",
    "print(f\"CSV saved: {OUTPUT_STAGING_CSV}\")\n",
    "print(f\"   Size: {csv_size:.1f} KB\")\n",
    "\n",
    "# Output to Parquet (optional - requires pyarrow or fastparquet)\n",
    "try:\n",
    "    trips_staging.to_parquet(OUTPUT_STAGING_PARQUET, index=False)\n",
    "    parquet_size = os.path.getsize(OUTPUT_STAGING_PARQUET) / 1024  # KB\n",
    "    print(f\"\\nParquet saved: {OUTPUT_STAGING_PARQUET}\")\n",
    "    print(f\"   Size: {parquet_size:.1f} KB\")\n",
    "    print(f\"   Compression ratio: {csv_size/parquet_size:.1f}x\")\n",
    "except ImportError:\n",
    "    print(\"\\nParquet output skipped (pyarrow not installed).\")\n",
    "    print(\"   To enable: pip install pyarrow\")\n",
    "    print(\"   CSV output is sufficient for this exercise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0bba4",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Verify Output\n",
    "\n",
    "Read back the output file to confirm it was written correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b498d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Verifying output...\n",
      "--------------------------------------------------\n",
      "Read back 2,500 rows from CSV\n",
      "Columns match: True\n",
      "\n",
      "First 3 rows of staged data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>origin_station_id</th>\n",
       "      <th>destination_station_id</th>\n",
       "      <th>board_datetime</th>\n",
       "      <th>alight_datetime</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>...</th>\n",
       "      <th>zones_charged</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>base_fare_cad</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>discount_amount_cad</th>\n",
       "      <th>yvr_addfare_cad</th>\n",
       "      <th>total_fare_cad</th>\n",
       "      <th>on_time_arrival</th>\n",
       "      <th>service_disruption</th>\n",
       "      <th>polyline_stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T100000</td>\n",
       "      <td>R33247</td>\n",
       "      <td>R111</td>\n",
       "      <td>bus</td>\n",
       "      <td>S021</td>\n",
       "      <td>S004</td>\n",
       "      <td>2024-01-31 10:45:08</td>\n",
       "      <td>2024-01-31 11:12:09</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.26</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S001|S025|S009|S008|S009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T100001</td>\n",
       "      <td>R43159</td>\n",
       "      <td>R033</td>\n",
       "      <td>bus</td>\n",
       "      <td>S005</td>\n",
       "      <td>S025</td>\n",
       "      <td>2024-08-08 00:16:41</td>\n",
       "      <td>2024-08-08 00:44:35</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11.66</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>S004|S023|S025|S030|S018|S003|S020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T100002</td>\n",
       "      <td>R18110</td>\n",
       "      <td>R001</td>\n",
       "      <td>bus</td>\n",
       "      <td>S014</td>\n",
       "      <td>S002</td>\n",
       "      <td>2024-05-28 02:42:12</td>\n",
       "      <td>2024-05-28 03:14:48</td>\n",
       "      <td>CA</td>\n",
       "      <td>BC</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.35</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>S001|S004|S008|S009|S018|S021|S001|S019|S007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id rider_id route_id mode origin_station_id destination_station_id  \\\n",
       "0  T100000   R33247     R111  bus              S021                   S004   \n",
       "1  T100001   R43159     R033  bus              S005                   S025   \n",
       "2  T100002   R18110     R001  bus              S014                   S002   \n",
       "\n",
       "        board_datetime      alight_datetime country province  ...  \\\n",
       "0  2024-01-31 10:45:08  2024-01-31 11:12:09      CA       BC  ...   \n",
       "1  2024-08-08 00:16:41  2024-08-08 00:44:35      CA       BC  ...   \n",
       "2  2024-05-28 02:42:12  2024-05-28 03:14:48      CA       BC  ...   \n",
       "\n",
       "  zones_charged distance_km  base_fare_cad  discount_rate  \\\n",
       "0             1        7.26           3.32           0.00   \n",
       "1             1       11.66           3.17           0.00   \n",
       "2             1       15.35           3.12           0.32   \n",
       "\n",
       "   discount_amount_cad  yvr_addfare_cad  total_fare_cad  on_time_arrival  \\\n",
       "0                  0.0              0.0            3.32             True   \n",
       "1                  0.0              0.0            3.17             True   \n",
       "2                  1.0              0.0            2.12            False   \n",
       "\n",
       "   service_disruption                             polyline_stations  \n",
       "0               False                      S001|S025|S009|S008|S009  \n",
       "1               False            S004|S023|S025|S030|S018|S003|S020  \n",
       "2               False  S001|S004|S008|S009|S018|S021|S001|S019|S007  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========= STEP 6: Verify output\n",
    "print(\"Step 6: Verifying output...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Read back the CSV\n",
    "trips_verify = pd.read_csv(OUTPUT_STAGING_CSV)\n",
    "\n",
    "print(f\"Read back {len(trips_verify):,} rows from CSV\")\n",
    "print(f\"Columns match: {list(trips_verify.columns) == output_cols}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst 3 rows of staged data:\")\n",
    "display(trips_verify.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Clean Up\n",
    "\n",
    "Close the database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cleanup-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL connection closed.\n"
     ]
    }
   ],
   "source": [
    "# ========= STEP 7: Clean up\n",
    "engine.dispose()\n",
    "print(\"PostgreSQL connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Generate a final summary report of the ETL job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ETL JOB SUMMARY: Trips to Staging\n",
      "============================================================\n",
      "\n",
      "Source:           PostgreSQL localhost:5432/postgres\n",
      "Table:            raw_trips\n",
      "Output CSV:       /tmp/stg_trips_raw.csv\n",
      "Output Parquet:   /tmp/stg_trips_raw.parquet\n",
      "\n",
      "Records:\n",
      "  - Extracted:    2,500\n",
      "  - Transformed:  2,500\n",
      "  - Staged:       2,500\n",
      "\n",
      "Data Quality:\n",
      "  - Columns:      23 (all expected)\n",
      "  - Null trip_id: 0\n",
      "  - Date range:   2024-01-01 01:08:58 to 2025-06-29 20:37:07\n",
      "\n",
      "Status:           SUCCESS\n",
      "Completed:        2025-12-15T19:15:38.852136\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========= Final Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"ETL JOB SUMMARY: Trips to Staging\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Source:           PostgreSQL {PG_HOST}:{PG_PORT}/{PG_DB}\n",
    "Table:            raw_trips\n",
    "Output CSV:       {OUTPUT_STAGING_CSV}\n",
    "Output Parquet:   {OUTPUT_STAGING_PARQUET}\n",
    "\n",
    "Records:\n",
    "  - Extracted:    {len(trips_raw):,}\n",
    "  - Transformed:  {len(trips_clean):,}\n",
    "  - Staged:       {len(trips_staging):,}\n",
    "\n",
    "Data Quality:\n",
    "  - Columns:      {len(trips_staging.columns)} (all expected)\n",
    "  - Null trip_id: {trips_staging['trip_id'].isna().sum()}\n",
    "  - Date range:   {trips_staging['board_datetime'].min()} to {trips_staging['board_datetime'].max()}\n",
    "\n",
    "Status:           SUCCESS\n",
    "Completed:        {datetime.now().isoformat()}\n",
    "\"\"\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
