{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Lesson 2: Exercise 1 Solution - Write DDL for Riders\n",
    "\n",
    "## Goal\n",
    "\n",
    "Design a **slowly-changing snapshot** dimension for riders with a surrogate key, distribution and sort strategy optimized for joins from rider-centric facts.\n",
    "\n",
    "## What You Will Build\n",
    "\n",
    "Create `dw_dim_rider` with:\n",
    "\n",
    "- `rider_sk` (surrogate key, `IDENTITY`)\n",
    "- Natural key `rider_id` (string)\n",
    "- Attributes: `rider_segment`, `effective_from`, `effective_to`, `is_current`\n",
    "- Compression encodings\n",
    "- Distribution and sort keys to support joins by rider\n",
    "\n",
    "### Acceptance Criteria\n",
    "\n",
    "- Table created successfully in Redshift\n",
    "- `rider_sk` is `IDENTITY(1,1)` and `PRIMARY KEY`\n",
    "- Distribution favors collocating rider-centric facts\n",
    "- Sort key supports common lookups by rider\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a86cfc",
   "metadata": {},
   "source": [
    "## Lesson 2 Exercise 1: Write DDL for Riders Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "Run this cell first to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "   - pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# ========= Imports\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"   - pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "Configure your Redshift connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "   - AWS Region: us-east-1\n",
      "   - Redshift: dev (workgroup: udacity-dwh-wg)\n",
      "\n",
      "   AWS credentials found (Key ID: ASIA54I5...)\n",
      "   AWS session token found (temporary credentials)\n"
     ]
    }
   ],
   "source": [
    "# ========= CONFIG (edit for your environment)\n",
    "# Set your AWS credentials in the aws_config.py file\n",
    "from aws_config import *  # This sets all AWS env vars\n",
    "\n",
    "# ---- Read configuration from environment\n",
    "AWS_ACCESS_KEY_ID           = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY       = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN           = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "AWS_REGION                  = os.getenv(\"AWS_REGION\")\n",
    "REDSHIFT_DATABASE           = os.getenv(\"REDSHIFT_DATABASE\")\n",
    "REDSHIFT_WORKGROUP          = os.getenv(\"REDSHIFT_WORKGROUP\")\n",
    "REDSHIFT_SECRET_ARN         = os.getenv(\"REDSHIFT_SECRET_ARN\")            # Optional\n",
    "REDSHIFT_CLUSTER_IDENTIFIER = os.getenv(\"REDSHIFT_CLUSTER_IDENTIFIER\")    # For provisioned\n",
    "REDSHIFT_DB_USER            = os.getenv(\"REDSHIFT_DB_USER\")               # For provisioned\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"   - AWS Region: {AWS_REGION}\")\n",
    "print(f\"   - Redshift: {REDSHIFT_DATABASE} (workgroup: {REDSHIFT_WORKGROUP})\")\n",
    "print()\n",
    "if AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY:\n",
    "    print(f\"   AWS credentials found (Key ID: {AWS_ACCESS_KEY_ID[:8]}...)\")\n",
    "    if AWS_SESSION_TOKEN:\n",
    "        print(f\"   AWS session token found (temporary credentials)\")\n",
    "else:\n",
    "    print(\"   WARNING: AWS credentials NOT FOUND!\")\n",
    "    print(\"      Redshift operations will fail with 'NoCredentialsError'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "redshift-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Redshift Functions\n",
    "\n",
    "These helper functions match the patterns used in the final project. Learning them here will prepare you for the capstone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "redshift-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift functions defined: _rs_kwargs(), rs_exec()\n"
     ]
    }
   ],
   "source": [
    "# ========= Redshift Functions\n",
    "\n",
    "session_boto = boto3.Session(region_name=AWS_REGION)\n",
    "rsd = session_boto.client(\"redshift-data\", region_name=AWS_REGION)\n",
    "\n",
    "\n",
    "def _rs_kwargs() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Shared Redshift Data API connection args.\n",
    "    \n",
    "    Supports both:\n",
    "    - Serverless: uses WorkgroupName (and optionally SecretArn)\n",
    "    - Provisioned: uses ClusterIdentifier and DbUser\n",
    "    \"\"\"\n",
    "    base = dict(Database=REDSHIFT_DATABASE)\n",
    "    if REDSHIFT_WORKGROUP:\n",
    "        base[\"WorkgroupName\"] = REDSHIFT_WORKGROUP\n",
    "        if REDSHIFT_SECRET_ARN:\n",
    "            base[\"SecretArn\"] = REDSHIFT_SECRET_ARN\n",
    "    elif REDSHIFT_CLUSTER_IDENTIFIER and REDSHIFT_DB_USER:\n",
    "        base[\"ClusterIdentifier\"] = REDSHIFT_CLUSTER_IDENTIFIER\n",
    "        base[\"DbUser\"] = REDSHIFT_DB_USER\n",
    "    else:\n",
    "        raise RuntimeError(\"Configure Redshift serverless OR provisioned for Data API.\")\n",
    "    return base\n",
    "\n",
    "\n",
    "def rs_exec(sql: str, params: List[Dict[str, Any]] = None, return_results=False, timeout_s=900):\n",
    "    \"\"\"\n",
    "    Execute SQL on Redshift via the Data API.\n",
    "    \n",
    "    Args:\n",
    "        sql: SQL statement to execute\n",
    "        params: Optional list of parameter dicts for parameterized queries\n",
    "        return_results: If True, fetch and return query results\n",
    "        timeout_s: Maximum seconds to wait for query completion (default 15 min)\n",
    "    \n",
    "    Returns:\n",
    "        List of dicts if return_results=True or query is SELECT, else None\n",
    "    \"\"\"\n",
    "    sql = sql.strip()\n",
    "    if not sql:\n",
    "        return None\n",
    "    \n",
    "    # Build request kwargs\n",
    "    kwargs = _rs_kwargs()\n",
    "    kwargs[\"Sql\"] = sql\n",
    "    if params:\n",
    "        kwargs[\"Parameters\"] = params\n",
    "    \n",
    "    # Execute statement\n",
    "    sid = rsd.execute_statement(**kwargs)[\"Id\"]\n",
    "    \n",
    "    # Poll for completion\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        d = rsd.describe_statement(Id=sid)\n",
    "        if d[\"Status\"] in (\"FINISHED\", \"FAILED\", \"ABORTED\"):\n",
    "            break\n",
    "        if time.time() - start > timeout_s:\n",
    "            raise TimeoutError(\"Redshift statement timeout\")\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Check for errors\n",
    "    if d[\"Status\"] != \"FINISHED\":\n",
    "        raise RuntimeError(f\"Redshift SQL failed: {d.get('Error')}\\n---\\n{sql}\")\n",
    "    \n",
    "    # Return results for SELECT queries or when explicitly requested\n",
    "    if return_results or sql.lower().startswith(\"select\"):\n",
    "        out, next_token = [], None\n",
    "        while True:\n",
    "            args = dict(Id=sid)\n",
    "            if next_token:\n",
    "                args[\"NextToken\"] = next_token\n",
    "            r = rsd.get_statement_result(**args)\n",
    "            cols = [c[\"name\"] for c in r[\"ColumnMetadata\"]]\n",
    "            for rec in r[\"Records\"]:\n",
    "                row = []\n",
    "                for cell in rec:\n",
    "                    row.append(next(iter(cell.values())))\n",
    "                out.append(dict(zip(cols, row)))\n",
    "            next_token = r.get(\"NextToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "        return out\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"Redshift functions defined: _rs_kwargs(), rs_exec()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddl-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Design the dim_rider Table DDL\n",
    "\n",
    "Define the DDL for the rider dimension table with:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|----------|\n",
    "| **Surrogate key** (`rider_sk`) | Warehouse-generated, auto-incrementing ID |\n",
    "| **Natural key** (`rider_id`) | Original ID from source system |\n",
    "| **Attributes** (`rider_segment`) | Descriptive fields for analysis |\n",
    "| **SCD fields** | `effective_from`, `effective_to`, `is_current` for slowly changing dimension support |\n",
    "| **DISTKEY/SORTKEY** | Both on `rider_id` for fast joins during fact loading |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddl-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDL for dim_rider:\n",
      "============================================================\n",
      "\n",
      "-- =============================================================\n",
      "-- public.dw_dim_rider\n",
      "-- Grain: 1 row per rider (current snapshot with SCD support)\n",
      "-- =============================================================\n",
      "\n",
      "DROP TABLE IF EXISTS public.dw_dim_rider;\n",
      "\n",
      "CREATE TABLE public.dw_dim_rider (\n",
      "    -- Surrogate key (warehouse-generated)\n",
      "    rider_sk        BIGINT IDENTITY(1,1),\n",
      "    \n",
      "    -- Natural key (from source system)\n",
      "    rider_id        VARCHAR(32)  ENCODE zstd,\n",
      "    \n",
      "    -- Descriptive attributes\n",
      "    rider_segment   VARCHAR(16)  ENCODE zstd,\n",
      "    \n",
      "    -- Slowly Changing Dimension (SCD) tracking fields\n",
      "    effective_from  TIMESTAMP    ENCODE zstd,\n",
      "    effective_to    TIMESTAMP    ENCODE zstd,\n",
      "    is_current      BOOLEAN      ENCODE zstd,\n",
      "    \n",
      "    -- Primary key constraint\n",
      "    PRIMARY KEY (rider_sk)\n",
      ")\n",
      "-- Collocate rider-centric joins by distributing on the natural key\n",
      "DISTKEY (rider_id)\n",
      "-- Speed up point lookups and range scans by rider_id\n",
      "SORTKEY (rider_id);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DDL_DIM_RIDER = \"\"\"\n",
    "-- =============================================================\n",
    "-- public.dw_dim_rider\n",
    "-- Grain: 1 row per rider (current snapshot with SCD support)\n",
    "-- =============================================================\n",
    "\n",
    "DROP TABLE IF EXISTS public.dw_dim_rider;\n",
    "\n",
    "CREATE TABLE public.dw_dim_rider (\n",
    "    -- Surrogate key (warehouse-generated)\n",
    "    rider_sk        BIGINT IDENTITY(1,1),\n",
    "    \n",
    "    -- Natural key (from source system)\n",
    "    rider_id        VARCHAR(32)  ENCODE zstd,\n",
    "    \n",
    "    -- Descriptive attributes\n",
    "    rider_segment   VARCHAR(16)  ENCODE zstd,\n",
    "    \n",
    "    -- Slowly Changing Dimension (SCD) tracking fields\n",
    "    effective_from  TIMESTAMP    ENCODE zstd,\n",
    "    effective_to    TIMESTAMP    ENCODE zstd,\n",
    "    is_current      BOOLEAN      ENCODE zstd,\n",
    "    \n",
    "    -- Primary key constraint\n",
    "    PRIMARY KEY (rider_sk)\n",
    ")\n",
    "-- Collocate rider-centric joins by distributing on the natural key\n",
    "DISTKEY (rider_id)\n",
    "-- Speed up point lookups and range scans by rider_id\n",
    "SORTKEY (rider_id);\n",
    "\"\"\"\n",
    "\n",
    "print(\"DDL for dim_rider:\")\n",
    "print(\"=\" * 60)\n",
    "print(DDL_DIM_RIDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execute-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Execute the DDL\n",
    "\n",
    "Create the `dw_dim_rider` table in Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "execute-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table public.dw_dim_rider created successfully!\n"
     ]
    }
   ],
   "source": [
    "rs_exec(DDL_DIM_RIDER)\n",
    "print(\"Table public.dw_dim_rider created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Validate the Table Structure\n",
    "\n",
    "Query the information schema to verify the table was created with the correct columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "validate-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Structure for dw_dim_rider:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>character_maximum_length</th>\n",
       "      <th>is_nullable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rider_sk</td>\n",
       "      <td>bigint</td>\n",
       "      <td>True</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rider_id</td>\n",
       "      <td>character varying</td>\n",
       "      <td>32</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rider_segment</td>\n",
       "      <td>character varying</td>\n",
       "      <td>16</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effective_from</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "      <td>True</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>effective_to</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "      <td>True</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is_current</td>\n",
       "      <td>boolean</td>\n",
       "      <td>True</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column_name                    data_type character_maximum_length  \\\n",
       "0        rider_sk                       bigint                     True   \n",
       "1        rider_id            character varying                       32   \n",
       "2   rider_segment            character varying                       16   \n",
       "3  effective_from  timestamp without time zone                     True   \n",
       "4    effective_to  timestamp without time zone                     True   \n",
       "5      is_current                      boolean                     True   \n",
       "\n",
       "  is_nullable  \n",
       "0          NO  \n",
       "1         YES  \n",
       "2         YES  \n",
       "3         YES  \n",
       "4         YES  \n",
       "5         YES  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_sql = \"\"\"\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type,\n",
    "    character_maximum_length,\n",
    "    is_nullable\n",
    "FROM information_schema.columns\n",
    "WHERE table_schema = 'public'\n",
    "  AND table_name = 'dw_dim_rider'\n",
    "ORDER BY ordinal_position;\n",
    "\"\"\"\n",
    "\n",
    "columns = rs_exec(validation_sql, return_results=True)\n",
    "\n",
    "print(\"Table Structure for dw_dim_rider:\")\n",
    "print(\"-\" * 60)\n",
    "if columns:\n",
    "    df = pd.DataFrame(columns)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No columns found. Check if table was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "keys-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Check Distribution and Sort Keys\n",
    "\n",
    "Verify that the DISTKEY and SORTKEY were applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "keys-001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution and Sort Key Configuration:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>type</th>\n",
       "      <th>encoding</th>\n",
       "      <th>distkey</th>\n",
       "      <th>sortkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effective_from</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "      <td>zstd</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>effective_to</td>\n",
       "      <td>timestamp without time zone</td>\n",
       "      <td>zstd</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is_current</td>\n",
       "      <td>boolean</td>\n",
       "      <td>zstd</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rider_segment</td>\n",
       "      <td>character varying(16)</td>\n",
       "      <td>zstd</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rider_sk</td>\n",
       "      <td>bigint</td>\n",
       "      <td>az64</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rider_id</td>\n",
       "      <td>character varying(32)</td>\n",
       "      <td>zstd</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column                         type encoding  distkey  sortkey\n",
       "0  effective_from  timestamp without time zone     zstd    False        0\n",
       "1    effective_to  timestamp without time zone     zstd    False        0\n",
       "2      is_current                      boolean     zstd    False        0\n",
       "3   rider_segment        character varying(16)     zstd    False        0\n",
       "4        rider_sk                       bigint     az64    False        0\n",
       "5        rider_id        character varying(32)     zstd     True        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "properties_sql = \"\"\"\n",
    "SELECT \n",
    "    \"column\",\n",
    "    type,\n",
    "    encoding,\n",
    "    distkey,\n",
    "    sortkey\n",
    "FROM pg_table_def\n",
    "WHERE schemaname = 'public'\n",
    "  AND tablename = 'dw_dim_rider'\n",
    "ORDER BY sortkey, \"column\";\n",
    "\"\"\"\n",
    "\n",
    "properties = rs_exec(properties_sql, return_results=True)\n",
    "\n",
    "print(\"Distribution and Sort Key Configuration:\")\n",
    "print(\"-\" * 60)\n",
    "if properties:\n",
    "    df = pd.DataFrame(properties)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"Could not retrieve table properties.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rationale-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Design Rationale\n",
    "\n",
    "### Why This Design?\n",
    "\n",
    "| Design Choice | Rationale |\n",
    "|---------------|------------|\n",
    "| **Surrogate key (`rider_sk`)** | Keeps fact tables narrow and stable. Source IDs can change; surrogate keys don't. |\n",
    "| **DISTKEY on `rider_id`** | Collocates rows for rider-centric queries. When loading facts, we join on `rider_id` to get `rider_sk`. |\n",
    "| **SORTKEY on `rider_id`** | Accelerates equality predicates and merge joins for common lookups. |\n",
    "| **SCD fields** | `effective_from`, `effective_to`, `is_current` support tracking rider attribute changes over time. |\n",
    "| **ENCODE zstd** | Efficient compression for string and timestamp columns. |\n",
    "\n",
    "### Grain\n",
    "\n",
    "**1 row = 1 rider** (current snapshot, with history tracked via SCD fields)\n",
    "\n",
    "### Conformed Dimension\n",
    "\n",
    "This `dw_dim_rider` table is designed to be **conformed** across multiple fact tables:\n",
    "- `fact_trips` (rider who took the trip)\n",
    "- `fact_events` (rider associated with the event)\n",
    "- `fact_graph_edges` (riders in relationships)\n",
    "\n",
    "All three facts will reference `rider_sk`, enabling consistent cross-dataset analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
