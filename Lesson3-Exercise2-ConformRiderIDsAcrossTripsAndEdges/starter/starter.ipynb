{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Lesson 3: Exercise 2 - Conform Rider IDs Across PostgreSQL and Neo4j\n",
    "\n",
    "## Goal\n",
    "\n",
    "Create a **conformed rider dimension** by reconciling rider identifiers across PostgreSQL (trips) and Neo4j (graph edges). This ensures that analytics can join trips and graph edges using a single, consistent rider key.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You should have completed:\n",
    "- **Lesson 1, Exercise 1**: Connected to PostgreSQL (`raw_trips` table)\n",
    "- **Lesson 1, Exercise 3**: Connected to Neo4j (graph edges)\n",
    "- **Lesson 2, Exercise 1**: Designed the `dw_dim_rider` table\n",
    "\n",
    "## What You Will Build\n",
    "\n",
    "A Pandas-based conformance process that:\n",
    "\n",
    "1. Extracts rider identifiers from PostgreSQL trips\n",
    "2. Extracts rider identifiers from Neo4j graph edges\n",
    "3. Identifies common and unique riders across systems\n",
    "4. Creates a unified rider dimension table\n",
    "5. Validates referential integrity\n",
    "\n",
    "### Why Conformance Matters\n",
    "\n",
    "Different source systems often use different naming conventions or ID formats. For example:\n",
    "- Trips use `rider_id` directly\n",
    "- Graph edges reference riders as `from_node_id` with `from_node_type = 'Rider'`\n",
    "- Graph edges also have `rider_segment` attributes not present in trips\n",
    "\n",
    "Conformance creates a single source of truth for each entity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Dependencies\n",
    "\n",
    "Run this cell first to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Imports\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List, Set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"   - pandas version: {pd.__version__}\")\n",
    "print(f\"   - numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "\n",
    "**Important:** These credentials match the populate scripts from Lesson 1. Update only if your environment differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= PostgreSQL Configuration ==========\n",
    "# These match the populate-postgres.py script from Lesson 1.\n",
    "\n",
    "PG_HOST = \"localhost\"      # Database host\n",
    "PG_PORT = \"5432\"           # Database port\n",
    "PG_DB = \"postgres\"         # Database name (populate script uses 'postgres')\n",
    "PG_USER = \"temp\"           # User from populate-postgres.py\n",
    "PG_PASSWORD = \"temp\"       # Password from populate-postgres.py\n",
    "\n",
    "PG_URI = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "# ========= Neo4j Configuration ==========\n",
    "# These match the populate-neo4j.py script from Lesson 1.\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"  # Neo4j connection URI\n",
    "NEO4J_USER = \"neo4j\"                 # User from populate-neo4j.py\n",
    "NEO4J_PASSWORD = \"neo4jpass\"         # Password from populate-neo4j.py\n",
    "\n",
    "# Output path\n",
    "OUTPUT_DIM_RIDER = \"/tmp/dim_rider_conformed.csv\"\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"   - PostgreSQL: {PG_HOST}:{PG_PORT}/{PG_DB} (user: {PG_USER})\")\n",
    "print(f\"   - Neo4j: {NEO4J_URI} (user: {NEO4J_USER})\")\n",
    "print(f\"   - Output: {OUTPUT_DIM_RIDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "populate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Populate the Databases\n",
    "\n",
    "Run these cells to populate PostgreSQL and Neo4j with sample data (if not already done)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "populate-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python populate-postgres.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "populate-002",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python populate-neo4j.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions\n",
    "\n",
    "Utility functions for data cleaning and Neo4j queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Helper Functions\n",
    "\n",
    "def trim_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize text fields and handle NaN values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for c in df.select_dtypes(include=['object']).columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        # Use mask instead of replace to avoid FutureWarning\n",
    "        df[c] = df[c].mask(df[c].isin(['nan', 'None', 'NaN', '']), np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_cypher(session, cypher: str, **params) -> list:\n",
    "    \"\"\"\n",
    "    Execute a Cypher query and return results as list of dicts.\n",
    "    \"\"\"\n",
    "    result = session.run(cypher, **params)\n",
    "    return [record.data() for record in result]\n",
    "\n",
    "\n",
    "print(\"Helper functions defined: trim_df(), run_cypher()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pg-extract-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Extract Riders from PostgreSQL\n",
    "\n",
    "Get all unique rider IDs from the `raw_trips` table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pg-extract-todo",
   "metadata": {},
   "source": [
    "**TODO**: Write a SQL query to extract unique rider IDs from `raw_trips` along with:\n",
    "- Count of trips per rider\n",
    "- First trip datetime\n",
    "- Last trip datetime\n",
    "\n",
    "Use GROUP BY on rider_id and filter out NULL rider_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pg-extract-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 1: Extract riders from PostgreSQL\n",
    "print(\"Step 1: Extracting riders from PostgreSQL...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "pg_engine = create_engine(PG_URI)\n",
    "\n",
    "# TODO: Write SQL to extract unique rider IDs with trip count and date range\n",
    "SQL_RIDERS = \"\"\"\n",
    "-- TODO: Write your SELECT statement here\n",
    "-- Include: rider_id, trip_count, first_trip, last_trip\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with pg_engine.connect() as conn:\n",
    "    pg_riders = pd.read_sql(text(SQL_RIDERS), conn)\n",
    "\n",
    "pg_riders = trim_df(pg_riders)\n",
    "\n",
    "print(f\"Extracted {len(pg_riders):,} unique riders from PostgreSQL\")\n",
    "print(f\"\\nSample:\")\n",
    "display(pg_riders.head())\n",
    "\n",
    "# Store as set for later comparison\n",
    "trips_rider_ids = set(pg_riders['rider_id'].dropna().unique())\n",
    "print(f\"\\nUnique rider IDs: {len(trips_rider_ids):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neo4j-extract-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Extract Riders from Neo4j\n",
    "\n",
    "Get rider information from graph edges. In Neo4j, riders appear in multiple contexts:\n",
    "- As `from_node_id` when `from_node_type = 'Rider'`\n",
    "- As `to_node_id` when `to_node_type = 'Rider'`\n",
    "- In the `rider_id` property of certain edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neo4j-extract-todo",
   "metadata": {},
   "source": [
    "**TODO**: Write a Cypher query to extract rider information from Neo4j. You can either:\n",
    "1. Query Rider nodes directly: `MATCH (r:Rider) RETURN r.id, r.rider_segment`\n",
    "2. Or extract from edge properties if riders aren't separate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neo4j-extract-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 2: Extract riders from Neo4j\n",
    "print(\"Step 2: Extracting riders from Neo4j...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "import warnings\n",
    "# Suppress Neo4j informational notifications about null handling\n",
    "warnings.filterwarnings('ignore', message='.*AggregationSkippedNull.*')\n",
    "\n",
    "# Connect to Neo4j\n",
    "neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "# TODO: Write Cypher query to extract riders\n",
    "CYPHER_RIDERS = \"\"\"\n",
    "-- TODO: Write your Cypher query here\n",
    "-- Return: rider_id, rider_segment\n",
    "\"\"\"\n",
    "\n",
    "with neo4j_driver.session() as session:\n",
    "    results = run_cypher(session, CYPHER_RIDERS)\n",
    "\n",
    "neo4j_riders = pd.DataFrame(results)\n",
    "\n",
    "if not neo4j_riders.empty:\n",
    "    neo4j_riders = trim_df(neo4j_riders)\n",
    "    print(f\"Extracted {len(neo4j_riders):,} rider records from Neo4j\")\n",
    "    print(f\"\\nSample:\")\n",
    "    display(neo4j_riders.head())\n",
    "    \n",
    "    # Store unique rider IDs\n",
    "    edges_rider_ids = set(neo4j_riders['rider_id'].dropna().unique())\n",
    "    print(f\"\\nUnique rider IDs: {len(edges_rider_ids):,}\")\n",
    "else:\n",
    "    print(\"No riders found in Neo4j\")\n",
    "    edges_rider_ids = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyze-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Analyze Overlap Between Sources\n",
    "\n",
    "Compare rider IDs from both systems to understand the overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyze-todo",
   "metadata": {},
   "source": [
    "**TODO**: Use set operations to calculate:\n",
    "- Common riders (intersection): `trips_rider_ids & edges_rider_ids`\n",
    "- Trips-only riders (difference): `trips_rider_ids - edges_rider_ids`\n",
    "- Edges-only riders (difference): `edges_rider_ids - trips_rider_ids`\n",
    "- Total unique riders (union): `trips_rider_ids | edges_rider_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 3: Analyze overlap\n",
    "print(\"Step 3: Analyzing overlap between sources...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# TODO: Calculate overlap using set operations\n",
    "common_riders = set()    \n",
    "trips_only = set()      \n",
    "edges_only = set()       \n",
    "all_riders = set()       \n",
    "\n",
    "print(f\"OVERLAP ANALYSIS:\")\n",
    "print(f\"   PostgreSQL (trips):  {len(trips_rider_ids):,}\")\n",
    "print(f\"   Neo4j (edges):       {len(edges_rider_ids):,}\")\n",
    "print(f\"   ---\")\n",
    "print(f\"   Common to both:      {len(common_riders):,}\")\n",
    "print(f\"   Only in trips:       {len(trips_only):,}\")\n",
    "print(f\"   Only in edges:       {len(edges_only):,}\")\n",
    "print(f\"   Total unique:        {len(all_riders):,}\")\n",
    "\n",
    "# Overlap percentage\n",
    "if len(all_riders) > 0:\n",
    "    overlap_pct = len(common_riders) / len(all_riders) * 100\n",
    "    print(f\"\\n   Overlap rate: {overlap_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conform-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Build Conformed Rider Dimension\n",
    "\n",
    "Create a unified rider dimension that includes:\n",
    "- All unique rider IDs from both sources\n",
    "- Rider segment (from Neo4j where available)\n",
    "- Trip activity metrics (from PostgreSQL)\n",
    "- Source flags indicating where each rider appears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conform-todo",
   "metadata": {},
   "source": [
    "**TODO**: Build the conformed dimension by:\n",
    "\n",
    "1. Start with all unique rider_ids from `all_riders`\n",
    "2. Left join to `pg_riders` to get trip metrics\n",
    "3. Left join to `neo4j_riders` to get rider_segment\n",
    "4. Add boolean flags: `in_trips`, `in_edges`\n",
    "5. Fill missing segments with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conform-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 4: Build conformed dimension\n",
    "print(\"Step 4: Building conformed rider dimension...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# TODO: Create base DataFrame with all unique rider IDs\n",
    "\n",
    "\n",
    "# TODO: Left join to PostgreSQL data (trip metrics)\n",
    "\n",
    "\n",
    "# TODO: Add flag for riders in trips\n",
    "\n",
    "\n",
    "# TODO: Left join to Neo4j data (rider segment)\n",
    "if not neo4j_riders.empty:\n",
    "\n",
    "\n",
    "# TODO: Add flag for riders in edges\n",
    "\n",
    "\n",
    "# TODO: Fill missing trip counts with 0\n",
    "\n",
    "\n",
    "# TODO: Fill missing segments with 'Unknown'\n",
    "\n",
    "\n",
    "# Placeholder for now\n",
    "dim_rider_final = pd.DataFrame()\n",
    "\n",
    "print(f\"Conformed dimension created: {len(dim_rider_final):,} riders\")\n",
    "print(f\"\\nSample rows:\")\n",
    "display(dim_rider_final.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Validate the Conformed Dimension\n",
    "\n",
    "Ensure all source riders are captured and check referential integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 5: Validate\n",
    "print(\"Step 5: Validating conformed dimension...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check all source riders captured\n",
    "dim_rider_set = set(dim_rider_final['rider_id'].unique()) if not dim_rider_final.empty else set()\n",
    "trips_covered = trips_rider_ids.issubset(dim_rider_set)\n",
    "edges_covered = edges_rider_ids.issubset(dim_rider_set)\n",
    "\n",
    "print(f\"Coverage check:\")\n",
    "print(f\"   All trips riders captured: {trips_covered}\")\n",
    "print(f\"   All edges riders captured: {edges_covered}\")\n",
    "\n",
    "# Segment distribution\n",
    "if not dim_rider_final.empty and 'rider_segment' in dim_rider_final.columns:\n",
    "    print(f\"\\nRider segment distribution:\")\n",
    "    segment_dist = dim_rider_final['rider_segment'].value_counts()\n",
    "    for segment, count in segment_dist.items():\n",
    "        pct = count / len(dim_rider_final) * 100\n",
    "        print(f\"   {segment}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Output Conformed Dimension\n",
    "\n",
    "Save the conformed rider dimension for loading into the warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "output-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 6: Output\n",
    "print(\"Step 6: Outputting conformed dimension...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Save to CSV\n",
    "if not dim_rider_final.empty:\n",
    "    dim_rider_final.to_csv(OUTPUT_DIM_RIDER, index=False)\n",
    "    file_size = os.path.getsize(OUTPUT_DIM_RIDER) / 1024\n",
    "    \n",
    "    print(f\"Saved to: {OUTPUT_DIM_RIDER}\")\n",
    "    print(f\"File size: {file_size:.1f} KB\")\n",
    "    print(f\"Total riders: {len(dim_rider_final):,}\")\n",
    "else:\n",
    "    print(\"No data to save - complete the TODO sections above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Clean Up\n",
    "\n",
    "Close all database connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 7: Clean up\n",
    "pg_engine.dispose()\n",
    "neo4j_driver.close()\n",
    "print(\"Database connections closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "### Conformance Strategies\n",
    "\n",
    "1. **Union approach**: Combine all unique identifiers from all sources\n",
    "2. **Attribute enrichment**: Pull attributes from whichever source has them\n",
    "3. **Conflict resolution**: When sources disagree, use rules (e.g., most recent, most common)\n",
    "\n",
    "### Common Challenges\n",
    "\n",
    "- **ID format differences**: Some systems use prefixes (e.g., `R12345` vs `12345`)\n",
    "- **Case sensitivity**: `rider_001` vs `RIDER_001`\n",
    "- **Orphan records**: Riders that appear in edges but never took a trip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
